{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = Object.setPrototypeOf || {\n    __proto__: []\n  } instanceof Array && function (d, b) {\n    d.__proto__ = b;\n  } || function (d, b) {\n    for (var p in b) {\n      if (b.hasOwnProperty(p)) d[p] = b[p];\n    }\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __decorate = this && this.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n      r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n      d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) {\n    if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  }\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [0, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tfc = require(\"@tensorflow/tfjs-core\");\n\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\n\nvar K = require(\"../backend/tfjs_backend\");\n\nvar callbacks_1 = require(\"../callbacks\");\n\nvar errors_1 = require(\"../errors\");\n\nvar losses = require(\"../losses\");\n\nvar Metrics = require(\"../metrics\");\n\nvar optimizers = require(\"../optimizers\");\n\nvar generic_utils_1 = require(\"../utils/generic_utils\");\n\nvar math_utils_1 = require(\"../utils/math_utils\");\n\nvar executor_1 = require(\"./executor\");\n\nvar topology_1 = require(\"./topology\");\n\nfunction isDataTensor(x) {\n  return x instanceof tfjs_core_1.Tensor;\n}\n\nexports.isDataTensor = isDataTensor;\n\nfunction isDataArray(x) {\n  return Array.isArray(x);\n}\n\nexports.isDataArray = isDataArray;\n\nfunction isDataDict(x) {\n  return !isDataTensor(x) && !isDataArray(x);\n}\n\nexports.isDataDict = isDataDict;\n\nfunction standardizeInputData(data, names, shapes, checkBatchAxis, exceptionPrefix) {\n  if (checkBatchAxis === void 0) {\n    checkBatchAxis = true;\n  }\n\n  if (exceptionPrefix === void 0) {\n    exceptionPrefix = '';\n  }\n\n  if (names == null || names.length === 0) {\n    if (data != null) {\n      var gotUnexpectedData = false;\n\n      if (isDataArray(data) && data.length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (var key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        gotUnexpectedData = true;\n      }\n\n      if (gotUnexpectedData) {\n        throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \" expected no data, \" + (\"but got \" + data));\n      }\n    }\n\n    return [];\n  }\n\n  if (data == null) {\n    return names.map(function (name) {\n      return null;\n    });\n  }\n\n  var arrays;\n\n  if (isDataDict(data)) {\n    data = data;\n    arrays = [];\n\n    for (var _i = 0, names_1 = names; _i < names_1.length; _i++) {\n      var name_1 = names_1[_i];\n\n      if (data[name_1] == null) {\n        throw new errors_1.ValueError(\"No data provided for \\\"\" + name_1 + \"\\\". Need data for each key in: \" + (\"\" + names));\n      }\n\n      arrays.push(data[name_1]);\n    }\n  } else if (isDataArray(data)) {\n    data = data;\n\n    if (data.length !== names.length) {\n      throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" + \"Tensors that you are passing to your model is not the size the \" + (\"model expected. Expected to see \" + names.length + \" Tensor(s), but \") + (\"instead got the following list of Tensor(s): \" + data));\n    }\n\n    arrays = data;\n  } else {\n    data = data;\n\n    if (names.length > 1) {\n      throw new errors_1.ValueError(\"The model \" + exceptionPrefix + \" expects \" + names.length + \" Tensor(s), \" + (\"but only received one Tensor. Found: Tensor with shape \" + data.shape));\n    }\n\n    arrays = [data];\n  }\n\n  for (var i = 0; i < names.length; ++i) {\n    var array = arrays[i];\n\n    if (array.shape.length === 1) {\n      arrays[i] = K.expandDims(array, 1);\n    }\n  }\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have \" + shapes[i].length + \" dimension(s). but got array with \") + (\"shape \" + array.shape));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have shape [\" + shapes[i] + \"], but got array with shape \") + (\"[\" + array.shape + \"].\"));\n        }\n      }\n    }\n  }\n\n  return arrays;\n}\n\nexports.standardizeInputData = standardizeInputData;\n\nfunction checkArrayLengths(inputs, targets, weights) {\n  var setX = generic_utils_1.unique(inputs.map(function (input) {\n    return input.shape[0];\n  }));\n  setX.sort();\n  var setY = generic_utils_1.unique(targets.map(function (target) {\n    return target.shape[0];\n  }));\n  setY.sort();\n\n  if (setX.length > 1) {\n    throw new errors_1.ValueError(\"All input Tensors (x) should have the same number of samples. \" + \"Got array shapes: \" + (\"\" + JSON.stringify(inputs.map(function (input) {\n      return input.shape;\n    }))));\n  }\n\n  if (setY.length > 1) {\n    throw new errors_1.ValueError(\"All target Tensors (y) should have the same number of samples. \" + \"Got array shapes: \" + (\"\" + JSON.stringify(targets.map(function (target) {\n      return target.shape;\n    }))));\n  }\n\n  if (setX.length > 0 && setY.length > 0 && !tfjs_core_1.util.arraysEqual(setX, setY)) {\n    throw new errors_1.ValueError(\"Input Tensors should have the same number of samples as target \" + (\"Tensors. Found \" + setX[0] + \" input sample(s) and \" + setY[0] + \" target \") + \"sample(s).\");\n  }\n}\n\nexports.checkArrayLengths = checkArrayLengths;\n\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n  var keyLosses = [losses.meanSquaredError, losses.binaryCrossentropy, losses.categoricalCrossentropy];\n\n  for (var i = 0; i < targets.length; ++i) {\n    var y = targets[i];\n    var loss = lossFns[i];\n    var shape = outputShapes[i];\n\n    if (loss == null) {\n      continue;\n    }\n\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new errors_1.ValueError(\"You are passing a target array of shape \" + y.shape + \" while using \" + \"a loss 'categorical_crossentropy'. 'categorical_crossentropy'\" + \"expects targets to be binary matrices (1s and 0s) of shape \" + \"[samples, classes].\");\n      }\n    }\n\n    if (keyLosses.indexOf(loss) !== -1) {\n      var slicedYShape = y.shape.slice(1);\n      var slicedShape = shape.slice(1);\n\n      for (var j = 0; j < slicedYShape.length; ++j) {\n        var targetDim = slicedYShape[j];\n        var outDim = slicedShape[j];\n\n        if (outDim != null && targetDim !== outDim) {\n          throw new errors_1.ValueError(\"A target Tensor with shape \" + y.shape + \" was passed for an \" + (\"output of shape \" + shape + \", while using a loss function that \") + \"expects targets to have the same shape as the output.\");\n        }\n      }\n    }\n  }\n}\n\nfunction makeBatches(size, batchSize) {\n  var output = [];\n  var batchStart = 0;\n  var batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n\nexports.makeBatches = makeBatches;\n\nfunction sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(function (array) {\n      return K.sliceAlongFirstAxis(array, start, stop - start);\n    });\n  } else {\n    return K.sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n\nfunction sliceArraysByIndices(arrays, indices) {\n  if (arrays == null) {\n    return null;\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(function (array) {\n      return sliceArraysByIndices(array, indices);\n    });\n  } else {\n    return K.gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n  }\n}\n\nexports.sliceArraysByIndices = sliceArraysByIndices;\n\nfunction checkInputData(data, names, shapes, checkBatchAxis, exceptionPrefix) {\n  if (checkBatchAxis === void 0) {\n    checkBatchAxis = true;\n  }\n\n  if (exceptionPrefix === void 0) {\n    exceptionPrefix = '';\n  }\n\n  var arrays;\n\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" + \"Tensors that you are passing to your model is not the size the \" + (\"the model expected. Expected to see \" + names.length + \" Tensor(s),\") + (\" but instead got \" + data.length + \" Tensors(s).\"));\n    }\n\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new errors_1.ValueError(\"The model expects \" + names.length + \" \" + exceptionPrefix + \" Tensors, \" + \"but only received one Tensor. Found: array with shape \" + (JSON.stringify(data.shape) + \".\"));\n    }\n\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" + (\"to have \" + shapes[i].length + \" dimension(s), but got array with \") + (\"shape \" + JSON.stringify(array.shape)));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + (names[i] + \" to have shape \" + JSON.stringify(shapes[i]) + \" but \") + (\"got array with shape \" + JSON.stringify(array.shape) + \".\"));\n          }\n        }\n      }\n    }\n  }\n}\n\nfunction collectMetrics(metrics, outputNames) {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(function (name) {\n      return [];\n    });\n  }\n\n  if (Array.isArray(metrics)) {\n    return outputNames.map(function (name) {\n      return metrics;\n    });\n  } else if (metrics != null) {\n    var nestedMetrics = [];\n\n    for (var _i = 0, outputNames_1 = outputNames; _i < outputNames_1.length; _i++) {\n      var name_2 = outputNames_1[_i];\n      var outputMetrics = metrics.hasOwnProperty(name_2) ? metrics[name_2] : [];\n\n      if (!Array.isArray(outputMetrics)) {\n        outputMetrics = [outputMetrics];\n      }\n\n      nestedMetrics.push(outputMetrics);\n    }\n\n    return nestedMetrics;\n  } else {\n    throw new TypeError('Type of metrics argument not understood. Expected an Array or ' + 'Object, found: ' + metrics);\n  }\n}\n\nvar ModelLoggingVerbosity;\n\n(function (ModelLoggingVerbosity) {\n  ModelLoggingVerbosity[ModelLoggingVerbosity[\"SILENT\"] = 0] = \"SILENT\";\n  ModelLoggingVerbosity[ModelLoggingVerbosity[\"VERBOSE\"] = 1] = \"VERBOSE\";\n})(ModelLoggingVerbosity = exports.ModelLoggingVerbosity || (exports.ModelLoggingVerbosity = {}));\n\nvar Model = function (_super) {\n  __extends(Model, _super);\n\n  function Model(config) {\n    return _super.call(this, config) || this;\n  }\n\n  Model.prototype.getClassName = function () {\n    return 'Model';\n  };\n\n  Model.prototype.compile = function (config) {\n    var _this = this;\n\n    if (config.loss == null) {\n      config.loss = [];\n    }\n\n    this.loss = config.loss;\n\n    if (typeof config.optimizer === 'string') {\n      this.optimizer = optimizers.getOptimizer(config.optimizer);\n    } else {\n      if (!(config.optimizer instanceof tfjs_core_1.Optimizer)) {\n        throw new errors_1.ValueError(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n      }\n\n      this.optimizer = config.optimizer;\n    }\n\n    var lossFunctions = [];\n\n    if (!Array.isArray(config.loss) && typeof config.loss !== 'string' && typeof config.loss !== 'function') {\n      config.loss = config.loss;\n\n      for (var name_3 in config.loss) {\n        if (this.outputNames.indexOf(name_3) === -1) {\n          throw new errors_1.ValueError(\"Unknown entry in loss dictionary: \\\"\" + name_3 + \"\\\". Only expect the \" + (\"following keys: \" + this.outputNames));\n        }\n      }\n\n      for (var name_4 in this.outputNames) {\n        if (config.loss[name_4] == null) {\n          console.warn(\"Output \\\"\" + name_4 + \"\\\" is missing from loss dictionary. We assume \" + \"this was done on purpose, and we will not be expecting data \" + (\"to be passed to \" + name_4 + \" during training\"));\n        }\n\n        lossFunctions.push(losses.get(config.loss[name_4]));\n      }\n    } else if (Array.isArray(config.loss)) {\n      if (config.loss.length !== this.outputs.length) {\n        throw new errors_1.ValueError(\"When passing an Array as loss, it should have one entry per \" + (\"model output. The model has \" + this.outputs.length + \" output(s), \") + (\"but you passed loss=\" + config.loss + \".\"));\n      }\n\n      var theLosses = config.loss;\n      lossFunctions = theLosses.map(function (l) {\n        return losses.get(l);\n      });\n    } else {\n      var lossFunction_1 = losses.get(config.loss);\n      this.outputs.map(function (layer) {\n        lossFunctions.push(lossFunction_1);\n      });\n    }\n\n    this.lossFunctions = lossFunctions;\n    this.feedOutputNames = [];\n    this.feedOutputShapes = [];\n    this.feedLossFns = [];\n\n    for (var i = 0; i < this.outputs.length; ++i) {\n      var shape = this.internalOutputShapes[i];\n      var name_5 = this.outputNames[i];\n      this.feedOutputNames.push(name_5);\n      this.feedOutputShapes.push(shape);\n      this.feedLossFns.push(this.lossFunctions[i]);\n    }\n\n    var skipTargetIndices = [];\n    this.metrics = config.metrics;\n    this.metricsNames = ['loss'];\n    this.metricsTensors = [];\n    K.nameScope('loss', function () {\n      for (var i = 0; i < _this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        }\n\n        var weightedLoss = _this.lossFunctions[i];\n\n        if (_this.outputs.length > 1) {\n          _this.metricsTensors.push([weightedLoss, i]);\n\n          _this.metricsNames.push(_this.outputNames[i] + '_loss');\n        }\n      }\n    });\n    var nestedMetrics = collectMetrics(config.metrics, this.outputNames);\n\n    var appendMetric = function appendMetric(outputIndex, metricName, metricTensor) {\n      if (_this.outputNames.length > 1) {\n        metricName = _this.outputNames[outputIndex] + '_' + metricName;\n      }\n\n      _this.metricsNames.push(metricName);\n\n      _this.metricsTensors.push([metricTensor, outputIndex]);\n    };\n\n    K.nameScope('metric', function () {\n      var _loop_1 = function _loop_1(i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          return \"continue\";\n        }\n\n        var outputMetrics = nestedMetrics[i];\n\n        var handleMetrics = function handleMetrics(metrics) {\n          var metricNamePrefix = '';\n          var metricName;\n          var accFn;\n          var weightedMetricFn;\n\n          var _loop_2 = function _loop_2(metric) {\n            if (['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !== -1) {\n              var outputShape = _this.internalOutputShapes[i];\n\n              if (outputShape[outputShape.length - 1] === 1 || _this.lossFunctions[i] === losses.binaryCrossentropy) {\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryCrossentropy;\n                }\n              } else if (_this.lossFunctions[i] === losses.sparseCategoricalCrossentropy) {\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalCrossentropy;\n                }\n              } else {\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalCrossentropy;\n                }\n              }\n\n              var suffix = void 0;\n\n              if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                suffix = 'acc';\n              } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                suffix = 'ce';\n              }\n\n              weightedMetricFn = accFn;\n              metricName = metricNamePrefix + suffix;\n            } else {\n              var metricFn = Metrics.get(metric);\n              weightedMetricFn = metricFn;\n              metricName = metricNamePrefix + metric;\n            }\n\n            var metricResult;\n            K.nameScope(metricName, function () {\n              metricResult = weightedMetricFn;\n            });\n            appendMetric(i, metricName, metricResult);\n          };\n\n          for (var _i = 0, metrics_1 = metrics; _i < metrics_1.length; _i++) {\n            var metric = metrics_1[_i];\n\n            _loop_2(metric);\n          }\n        };\n\n        handleMetrics(outputMetrics);\n      };\n\n      for (var i = 0; i < _this.outputs.length; ++i) {\n        _loop_1(i);\n      }\n    });\n    this.collectedTrainableWeights = this.trainableWeights;\n  };\n\n  Model.prototype.checkTrainableWeightsConsistency = function () {\n    if (this.collectedTrainableWeights == null) {\n      return;\n    }\n\n    if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {\n      console.warn('Discrepancy between trainableweights and collected trainable ' + 'weights. Did you set `model.trainable` without calling ' + '`model.compile()` afterwards?');\n    }\n  };\n\n  Model.prototype.evaluate = function (x, y, config) {\n    if (config === void 0) {\n      config = {};\n    }\n\n    var batchSize = config.batchSize == null ? 32 : config.batchSize;\n    var standardizedOuts = this.standardizeUserData(x, y, true, batchSize);\n    var ins = standardizedOuts[0].concat(standardizedOuts[1]);\n    this.makeTestFunction();\n    var f = this.testFunction;\n    var testOuts = this.testLoop(f, ins, batchSize, config.verbose, config.steps);\n    return generic_utils_1.singletonOrArray(testOuts);\n  };\n\n  Model.prototype.checkNumSamples = function (ins, batchSize, steps, stepsName) {\n    if (stepsName === void 0) {\n      stepsName = 'steps';\n    }\n\n    var numSamples;\n\n    if (steps != null) {\n      numSamples = null;\n\n      if (batchSize != null) {\n        throw new errors_1.ValueError(\"If \" + stepsName + \" is set, batchSize must be null or undefined.\" + (\"Got batchSize = \" + batchSize));\n      }\n    } else if (ins != null) {\n      if (Array.isArray(ins)) {\n        numSamples = ins[0].shape[0];\n      } else {\n        numSamples = ins.shape[0];\n      }\n    } else {\n      throw new errors_1.ValueError(\"Either the input data should have a defined shape, or \" + (stepsName + \" shoud be specified.\"));\n    }\n\n    return numSamples;\n  };\n\n  Model.prototype.predictLoop = function (ins, batchSize, verbose) {\n    var _this = this;\n\n    if (batchSize === void 0) {\n      batchSize = 32;\n    }\n\n    if (verbose === void 0) {\n      verbose = false;\n    }\n\n    var numSamples = this.checkNumSamples(ins);\n\n    if (verbose) {\n      throw new errors_1.NotImplementedError('Verbose predictLoop() is not implemented yet.');\n    }\n\n    var batches = makeBatches(numSamples, batchSize);\n    var outs = [];\n\n    var _loop_3 = function _loop_3(batchIndex) {\n      var batchOuts = tfc.tidy(function () {\n        var batchStart = batches[batchIndex][0];\n        var batchEnd = batches[batchIndex][1];\n        var insBatch = sliceArrays(ins, batchStart, batchEnd);\n        var feeds = [];\n\n        if (Array.isArray(insBatch)) {\n          for (var i = 0; i < insBatch.length; ++i) {\n            feeds.push({\n              key: _this.inputs[i],\n              value: insBatch[i]\n            });\n          }\n        } else {\n          feeds.push({\n            key: _this.inputs[0],\n            value: insBatch\n          });\n        }\n\n        var feedDict = new executor_1.FeedDict(feeds);\n        return executor_1.execute(_this.outputs, feedDict);\n      });\n\n      if (batchIndex === 0) {\n        for (var _i = 0, batchOuts_1 = batchOuts; _i < batchOuts_1.length; _i++) {\n          var batchOut = batchOuts_1[_i];\n          outs.push(batchOut);\n        }\n      } else {\n        for (var i = 0; i < batchOuts.length; ++i) {\n          outs[i] = K.concatAlongFirstAxis(outs[i], batchOuts[i]);\n        }\n      }\n    };\n\n    for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n      _loop_3(batchIndex);\n    }\n\n    return generic_utils_1.singletonOrArray(outs);\n  };\n\n  Model.prototype.predict = function (x, config) {\n    if (config === void 0) {\n      config = {};\n    }\n\n    checkInputData(x, this.inputNames, this.feedInputShapes, false);\n    var batchSize = config.batchSize == null ? 32 : config.batchSize;\n    return this.predictLoop(x, batchSize);\n  };\n\n  Model.prototype.predictOnBatch = function (x) {\n    checkInputData(x, this.inputNames, this.feedInputShapes, true);\n    return this.predictLoop(x, x.shape[0]);\n  };\n\n  Model.prototype.standardizeUserData = function (x, y, checkBatchAxis, batchSize) {\n    if (checkBatchAxis === void 0) {\n      checkBatchAxis = true;\n    }\n\n    if (this.optimizer == null) {\n      throw new errors_1.RuntimeError('You must compile a model before training/testing. Use ' + 'Model.compile(modelCompileConfig).');\n    }\n\n    var outputShapes = [];\n\n    for (var i = 0; i < this.feedOutputShapes.length; ++i) {\n      var outputShape = this.feedOutputShapes[i];\n      var lossFn = this.feedLossFns[i];\n\n      if (lossFn === losses.sparseCategoricalCrossentropy) {\n        outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n      } else {\n        outputShapes.push(outputShape);\n      }\n    }\n\n    x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n    y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target');\n    checkArrayLengths(x, y, null);\n    checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n\n    if (this.stateful && batchSize != null && batchSize > 0) {\n      if (x[0].shape[0] % batchSize !== 0) {\n        throw new errors_1.ValueError(\"In a stateful network, you should only pass inputs with a \" + \"number of samples that is divisible by the batch size \" + (batchSize + \". Found: \" + x[0].shape[0] + \" sample(s).\"));\n      }\n    }\n\n    return [x, y, null];\n  };\n\n  Model.prototype.fitLoop = function (f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (initialEpoch === void 0) {\n      initialEpoch = 0;\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var _this = this;\n\n      var doValidation, numTrainSamples, indexArray, callbackList, _loop_4, epoch;\n\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            if (batchSize == null) {\n              batchSize = 32;\n            }\n\n            if (epochs == null) {\n              epochs = 100;\n            }\n\n            if (shuffle == null) {\n              shuffle = true;\n            }\n\n            if (initialEpoch == null) {\n              initialEpoch = 0;\n            }\n\n            doValidation = false;\n\n            if (valF != null && valIns != null) {\n              doValidation = true;\n            }\n\n            if (validationSteps != null) {\n              doValidation = true;\n\n              if (stepsPerEpoch == null) {\n                throw new errors_1.ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n              }\n            }\n\n            numTrainSamples = this.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n\n            if (numTrainSamples != null) {\n              indexArray = math_utils_1.range(0, numTrainSamples);\n            }\n\n            this.history = new callbacks_1.History();\n\n            if (callbacks == null) {\n              callbacks = [new callbacks_1.BaseLogger()];\n            } else {\n              callbacks = [new callbacks_1.BaseLogger()].concat(callbacks);\n            }\n\n            callbacks = callbacks.concat([this.history]);\n\n            if (verbose > 0) {\n              throw new errors_1.NotImplementedError('Verbose mode is not implemented yet.');\n            }\n\n            callbackList = new callbacks_1.CallbackList(callbacks);\n            callbackList.setModel(this);\n            callbackList.setParams({\n              epochs: epochs,\n              steps: stepsPerEpoch,\n              verbose: verbose,\n              doValidation: doValidation,\n              metrics: callbackMetrics\n            });\n            return [4, callbackList.onTrainBegin()];\n\n          case 1:\n            _a.sent();\n\n            _loop_4 = function _loop_4(epoch) {\n              var epochLogs, epochIndexArray1D_1, batches_1, _loop_5, batchIndex;\n\n              return __generator(this, function (_a) {\n                switch (_a.label) {\n                  case 0:\n                    return [4, callbackList.onEpochBegin(epoch)];\n\n                  case 1:\n                    _a.sent();\n\n                    epochLogs = {};\n                    if (!(stepsPerEpoch != null)) return [3, 2];\n                    throw new errors_1.NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n\n                  case 2:\n                    if (shuffle === 'batch') {\n                      throw new errors_1.NotImplementedError('batch shuffling is not implemneted yet');\n                    } else if (shuffle) {\n                      tfjs_core_1.util.shuffle(indexArray);\n                    }\n\n                    epochIndexArray1D_1 = tfjs_core_1.tensor1d(indexArray);\n                    batches_1 = makeBatches(numTrainSamples, batchSize);\n\n                    _loop_5 = function _loop_5(batchIndex) {\n                      var batchLogs;\n                      return __generator(this, function (_a) {\n                        switch (_a.label) {\n                          case 0:\n                            batchLogs = {};\n                            return [4, callbackList.onBatchBegin(batchIndex, batchLogs)];\n\n                          case 1:\n                            _a.sent();\n\n                            tfc.tidy(function () {\n                              var batchStart = batches_1[batchIndex][0];\n                              var batchEnd = batches_1[batchIndex][1];\n                              var batchIds = K.sliceAlongFirstAxis(epochIndexArray1D_1, batchStart, batchEnd - batchStart);\n                              batchLogs['batch'] = batchIndex;\n                              batchLogs['size'] = batchEnd - batchStart;\n                              var insBatch = sliceArraysByIndices(ins, batchIds);\n                              var outs = f(insBatch);\n\n                              for (var i = 0; i < outLabels.length; ++i) {\n                                var label = outLabels[i];\n                                var out = outs[i];\n                                batchLogs[label] = out;\n                                K.keep(out);\n                              }\n\n                              if (batchIndex === batches_1.length - 1) {\n                                if (doValidation) {\n                                  var valOuts = _this.testLoop(valF, valIns, batchSize);\n\n                                  for (var i = 0; i < outLabels.length; ++i) {\n                                    var label = outLabels[i];\n                                    var out = valOuts[i];\n                                    K.keep(out);\n                                    epochLogs['val_' + label] = out;\n                                  }\n                                }\n                              }\n                            });\n                            return [4, callbackList.onBatchEnd(batchIndex, batchLogs)];\n\n                          case 2:\n                            _a.sent();\n\n                            callbacks_1.disposeTensorsInLogs(batchLogs);\n                            return [2];\n                        }\n                      });\n                    };\n\n                    batchIndex = 0;\n                    _a.label = 3;\n\n                  case 3:\n                    if (!(batchIndex < batches_1.length)) return [3, 6];\n                    return [5, _loop_5(batchIndex)];\n\n                  case 4:\n                    _a.sent();\n\n                    _a.label = 5;\n\n                  case 5:\n                    ++batchIndex;\n                    return [3, 3];\n\n                  case 6:\n                    epochIndexArray1D_1.dispose();\n                    _a.label = 7;\n\n                  case 7:\n                    return [4, callbackList.onEpochEnd(epoch, epochLogs)];\n\n                  case 8:\n                    _a.sent();\n\n                    return [2];\n                }\n              });\n            };\n\n            epoch = initialEpoch;\n            _a.label = 2;\n\n          case 2:\n            if (!(epoch < epochs)) return [3, 5];\n            return [5, _loop_4(epoch)];\n\n          case 3:\n            _a.sent();\n\n            _a.label = 4;\n\n          case 4:\n            ++epoch;\n            return [3, 2];\n\n          case 5:\n            return [4, callbackList.onTrainEnd()];\n\n          case 6:\n            _a.sent();\n\n            return [4, this.history.syncData()];\n\n          case 7:\n            _a.sent();\n\n            return [2, this.history];\n        }\n      });\n    });\n  };\n\n  Model.prototype.testLoop = function (f, ins, batchSize, verbose, steps) {\n    if (verbose === void 0) {\n      verbose = 0;\n    }\n\n    var numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n    var outs = [];\n\n    if (verbose === 1) {\n      throw new errors_1.NotImplementedError('Verbose mode is not implemented yet.');\n    }\n\n    if (steps != null) {\n      throw new errors_1.NotImplementedError('steps mode in testLoop() is not implemented yet');\n    } else {\n      var batches = makeBatches(numSamples, batchSize);\n      var indexArray = tfjs_core_1.tensor1d(math_utils_1.range(0, numSamples));\n\n      for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        var batchStart = batches[batchIndex][0];\n        var batchEnd = batches[batchIndex][1];\n        var batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);\n        var insBatch = sliceArraysByIndices(ins, batchIds);\n        var batchOuts = f(insBatch);\n\n        if (batchIndex === 0) {\n          for (var i = 0; i < batchOuts.length; ++i) {\n            outs.push(K.getScalar(0));\n          }\n        }\n\n        for (var i = 0; i < batchOuts.length; ++i) {\n          var batchOut = batchOuts[i];\n          outs[i] = K.add(outs[i], K.scalarTimesArray(K.getScalar(batchEnd - batchStart), batchOut));\n        }\n      }\n\n      for (var i = 0; i < outs.length; ++i) {\n        outs[i] = K.divide(outs[i], K.getScalar(numSamples));\n      }\n    }\n\n    return outs;\n  };\n\n  Model.prototype.getDedupedMetricsNames = function () {\n    var outLabels = this.metricsNames;\n    var dedupedOutLabels = [];\n\n    for (var i = 0; i < outLabels.length; ++i) {\n      var label = outLabels[i];\n      var newLabel = label;\n\n      if (generic_utils_1.count(outLabels, label) > 1) {\n        var dupIndex = generic_utils_1.count(outLabels.slice(0, i), label);\n        newLabel += \"_\" + dupIndex;\n      }\n\n      dedupedOutLabels.push(newLabel);\n    }\n\n    return dedupedOutLabels;\n  };\n\n  Model.prototype.makeTestFunction = function () {\n    var _this = this;\n\n    this.testFunction = function (data) {\n      return tfc.tidy(function () {\n        var valOutputs = [];\n        var totalLoss;\n        var inputs = data.slice(0, _this.inputs.length);\n        var targets = data.slice(_this.inputs.length, _this.inputs.length + _this.outputs.length);\n        var feeds = [];\n\n        for (var i = 0; i < _this.inputs.length; ++i) {\n          feeds.push({\n            key: _this.inputs[i],\n            value: inputs[i]\n          });\n        }\n\n        var feedDict = new executor_1.FeedDict(feeds);\n        var outputs = executor_1.execute(_this.outputs, feedDict);\n\n        for (var i = 0; i < _this.lossFunctions.length; ++i) {\n          var lossFunction = _this.lossFunctions[i];\n          var loss = K.mean(lossFunction(targets[i], outputs[i]));\n\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = K.add(totalLoss, loss);\n          }\n\n          valOutputs.push(totalLoss);\n        }\n\n        for (var i = 0; i < _this.metricsTensors.length; ++i) {\n          var metric = _this.metricsTensors[i][0];\n          var outputIndex = _this.metricsTensors[i][1];\n          var meanMetric = K.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          valOutputs.push(meanMetric);\n        }\n\n        return valOutputs;\n      });\n    };\n  };\n\n  Model.prototype.fit = function (x, y, config) {\n    if (config === void 0) {\n      config = {};\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var _this = this;\n\n      var batchSize, standardizedOuts, inputs, targets, doValidation, valX, valY, valIns, valStandardized, splitAt, originalBatchSize, ins, trainFunction, outLabels, valFunction, callbackMetrics, callbacks;\n      return __generator(this, function (_a) {\n        batchSize = config.batchSize == null ? 32 : config.batchSize;\n        standardizedOuts = this.standardizeUserData(x, y, false, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        doValidation = false;\n\n        if (config.validationData != null && config.validationData.length > 0) {\n          doValidation = true;\n\n          if (config.validationData.length === 2) {\n            valX = config.validationData[0];\n            valY = config.validationData[1];\n          } else if (config.validationData.length === 3) {\n            throw new errors_1.NotImplementedError('validationData including sample weights is not supported yet.');\n          } else {\n            throw new errors_1.ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" + \"or 3 (valX, valY, valSampleWeight) items; \" + (config.validationData + \" is invalid.\"));\n          }\n\n          valStandardized = this.standardizeUserData(valX, valY, true, batchSize);\n          valX = valStandardized[0];\n          valY = valStandardized[1];\n          valIns = valX.concat(valY);\n        } else if (config.validationSplit != null && config.validationSplit > 0 && config.validationSplit < 1) {\n          doValidation = true;\n          splitAt = Math.floor(inputs[0].shape[0] * (1 - config.validationSplit));\n          originalBatchSize = inputs[0].shape[0];\n          valX = sliceArrays(inputs, splitAt, originalBatchSize);\n          inputs = sliceArrays(inputs, 0, splitAt);\n          valY = sliceArrays(targets, splitAt, originalBatchSize);\n          targets = sliceArrays(targets, 0, splitAt);\n          valIns = valX.concat(valY);\n        } else if (config.validationSteps != null) {\n          doValidation = true;\n        }\n\n        ins = inputs.concat(targets);\n        this.checkTrainableWeightsConsistency();\n\n        trainFunction = function trainFunction(data) {\n          var losses = [];\n          var lossValues = [];\n          var inputs = data.slice(0, _this.inputs.length);\n          var targets = data.slice(_this.inputs.length, _this.inputs.length + _this.outputs.length);\n          var metricsValues = [];\n\n          var totalLossFunction = function totalLossFunction() {\n            var feeds = [];\n\n            for (var i = 0; i < _this.inputs.length; ++i) {\n              feeds.push({\n                key: _this.inputs[i],\n                value: inputs[i]\n              });\n            }\n\n            var feedDict = new executor_1.FeedDict(feeds);\n            var outputs = executor_1.execute(_this.outputs, feedDict, {\n              'training': true\n            });\n            var totalLoss;\n\n            for (var i = 0; i < _this.lossFunctions.length; ++i) {\n              var lossFunction = _this.lossFunctions[i];\n              var loss = lossFunction(targets[i], outputs[i]);\n              losses.push(loss);\n              var meanLoss = K.mean(loss);\n              lossValues.push(meanLoss);\n\n              if (i === 0) {\n                totalLoss = loss;\n              } else {\n                totalLoss = K.add(totalLoss, loss);\n              }\n            }\n\n            for (var i = 0; i < _this.metricsTensors.length; ++i) {\n              var metric = _this.metricsTensors[i][0];\n              var outputIndex = _this.metricsTensors[i][1];\n              var meanMetric = K.mean(metric(targets[outputIndex], outputs[outputIndex]));\n              K.keep(meanMetric);\n              metricsValues.push(meanMetric);\n            }\n\n            totalLoss = K.mean(totalLoss);\n\n            _this.calculateLosses().forEach(function (regularizerLoss) {\n              totalLoss = K.add(totalLoss, regularizerLoss);\n            });\n\n            return totalLoss;\n          };\n\n          var variables = _this.collectedTrainableWeights.map(function (param) {\n            return param.read();\n          });\n\n          var returnCost = true;\n\n          var totalLossValue = _this.optimizer.minimize(totalLossFunction, returnCost, variables);\n\n          return [totalLossValue].concat(metricsValues);\n        };\n\n        outLabels = this.getDedupedMetricsNames();\n\n        if (doValidation) {\n          this.makeTestFunction();\n          valFunction = this.testFunction;\n          callbackMetrics = outLabels.slice().concat(outLabels.map(function (n) {\n            return 'val_' + n;\n          }));\n        } else {\n          valFunction = null;\n          valIns = [];\n          callbackMetrics = outLabels.slice();\n        }\n\n        callbacks = callbacks_1.standardizeCallbacks(config.callbacks);\n        return [2, this.fitLoop(trainFunction, ins, outLabels, batchSize, config.epochs, config.verbose, callbacks, valFunction, valIns, config.shuffle, callbackMetrics, null, null, null)];\n      });\n    });\n  };\n\n  __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes',\n    configParamIndices: [0]\n  })], Model.prototype, \"compile\", null);\n\n  __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes',\n    configParamIndices: [2]\n  })], Model.prototype, \"evaluate\", null);\n\n  __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes',\n    configParamIndices: [1]\n  })], Model.prototype, \"predict\", null);\n\n  __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes'\n  })], Model.prototype, \"predictOnBatch\", null);\n\n  __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes',\n    configParamIndices: [2]\n  })], Model.prototype, \"fit\", null);\n\n  Model = __decorate([tfjs_core_1.doc({\n    heading: 'Models',\n    subheading: 'Classes'\n  })], Model);\n  return Model;\n}(topology_1.Container);\n\nexports.Model = Model;\ngeneric_utils_1.ClassNameMap.register('Model', Model);","map":null,"metadata":{},"sourceType":"script"}