{"ast":null,"code":"\"use strict\";\n\nvar __decorate = this && this.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n      r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n      d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) {\n    if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  }\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [0, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar doc_1 = require(\"../doc\");\n\nvar environment_1 = require(\"../environment\");\n\nvar tensor_1 = require(\"../tensor\");\n\nvar tensor_util = require(\"../tensor_util\");\n\nvar util = require(\"../util\");\n\nvar axis_util_1 = require(\"./axis_util\");\n\nvar concat_1 = require(\"./concat\");\n\nvar operation_1 = require(\"./operation\");\n\nvar rand_1 = require(\"./rand\");\n\nvar ArrayOps = function () {\n  function ArrayOps() {}\n\n  ArrayOps.tensor = function (values, shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var inferredShape = util.inferShape(values);\n\n    if (shape != null && inferredShape.length !== 1) {\n      util.assertShapesMatch(shape, inferredShape, \"Error creating a new Tensor. \" + (\"Inferred shape (\" + inferredShape + \") does not match the \") + (\"provided shape (\" + shape + \"). \"));\n    }\n\n    if (!util.isTypedArray(values) && !Array.isArray(values)) {\n      values = [values];\n    }\n\n    shape = shape || inferredShape;\n    return tensor_1.Tensor.make(shape, {\n      values: toTypedArray(values, dtype)\n    }, dtype);\n  };\n\n  ArrayOps.scalar = function (value, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    if (util.isTypedArray(value) || Array.isArray(value)) {\n      throw new Error('Error creating a new Scalar: value must be a primitive ' + '(number|boolean)');\n    }\n\n    return ArrayOps.tensor(value, [], dtype);\n  };\n\n  ArrayOps.tensor1d = function (values, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var inferredShape = util.inferShape(values);\n\n    if (inferredShape.length !== 1) {\n      throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n\n    return ArrayOps.tensor(values, inferredShape, dtype);\n  };\n\n  ArrayOps.tensor2d = function (values, shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var inferredShape = util.inferShape(values);\n\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n      throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error('tensor2d() requires shape to be provided when `values` ' + 'are a flat/TypedArray');\n    }\n\n    shape = shape || inferredShape;\n    return ArrayOps.tensor(values, shape, dtype);\n  };\n\n  ArrayOps.tensor3d = function (values, shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var inferredShape = util.inferShape(values);\n\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n      throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error('tensor3d() requires shape to be provided when `values` ' + 'are a flat array');\n    }\n\n    shape = shape || inferredShape;\n    return ArrayOps.tensor(values, shape, dtype);\n  };\n\n  ArrayOps.tensor4d = function (values, shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var inferredShape = util.inferShape(values);\n\n    if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n      throw new Error('tensor4d() requires values to be number[][][][] or flat/TypedArray');\n    }\n\n    if (inferredShape.length === 1 && shape == null) {\n      throw new Error('tensor4d() requires shape to be provided when `values` ' + 'are a flat array');\n    }\n\n    shape = shape || inferredShape;\n    return ArrayOps.tensor(values, shape, dtype);\n  };\n\n  ArrayOps.ones = function (shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var values = makeOnesTypedArray(util.sizeFromShape(shape), dtype);\n    return tensor_1.Tensor.make(shape, {\n      values: values\n    }, dtype);\n  };\n\n  ArrayOps.zeros = function (shape, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var values = makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n    return tensor_1.Tensor.make(shape, {\n      values: values\n    }, dtype);\n  };\n\n  ArrayOps.fill = function (shape, value, dtype) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var values = util.getTypedArrayFromDType(dtype, util.sizeFromShape(shape));\n    values.fill(value);\n    return tensor_1.Tensor.make(shape, {\n      values: values\n    }, dtype);\n  };\n\n  ArrayOps.onesLike = function (x) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'onesLike');\n    return ArrayOps.ones(x.shape, x.dtype);\n  };\n\n  ArrayOps.zerosLike = function (x) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'zerosLike');\n    return ArrayOps.zeros(x.shape, x.dtype);\n  };\n\n  ArrayOps.clone = function (x) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'clone');\n\n    var der = function der(dy) {\n      return {\n        x: function x() {\n          return dy.toFloat();\n        }\n      };\n    };\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return tensor_1.Tensor.make(x.shape, {\n        dataId: x.dataId\n      }, x.dtype);\n    }, {\n      x: x\n    }, der);\n  };\n\n  ArrayOps.randomNormal = function (shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) {\n      mean = 0;\n    }\n\n    if (stdDev === void 0) {\n      stdDev = 1;\n    }\n\n    if (dtype != null && dtype === 'bool') {\n      throw new Error(\"Unsupported data type \" + dtype);\n    }\n\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, false, seed);\n    var res = ArrayOps.buffer(shape, dtype);\n\n    for (var i = 0; i < res.values.length; i++) {\n      res.values[i] = randGauss.nextValue();\n    }\n\n    return res.toTensor();\n  };\n\n  ArrayOps.truncatedNormal = function (shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) {\n      mean = 0;\n    }\n\n    if (stdDev === void 0) {\n      stdDev = 1;\n    }\n\n    if (dtype != null && dtype === 'bool') {\n      throw new Error(\"Unsupported data type \" + dtype);\n    }\n\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, true, seed);\n    var res = ArrayOps.buffer(shape, dtype);\n\n    for (var i = 0; i < res.values.length; i++) {\n      res.values[i] = randGauss.nextValue();\n    }\n\n    return res.toTensor();\n  };\n\n  ArrayOps.randomUniform = function (shape, minval, maxval, dtype) {\n    if (minval === void 0) {\n      minval = 0;\n    }\n\n    if (maxval === void 0) {\n      maxval = 1;\n    }\n\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    var res = ArrayOps.buffer(shape, dtype);\n\n    for (var i = 0; i < res.values.length; i++) {\n      res.values[i] = util.randUniform(minval, maxval);\n    }\n\n    return res.toTensor();\n  };\n\n  ArrayOps.rand = function (shape, randFunction, dtype) {\n    var size = util.sizeFromShape(shape);\n    var values = null;\n\n    if (dtype == null || dtype === 'float32') {\n      values = new Float32Array(size);\n    } else if (dtype === 'int32') {\n      values = new Int32Array(size);\n    } else if (dtype === 'bool') {\n      values = new Uint8Array(size);\n    } else {\n      throw new Error(\"Unknown data type \" + dtype);\n    }\n\n    for (var i = 0; i < size; i++) {\n      values[i] = randFunction();\n    }\n\n    return tensor_1.Tensor.make(shape, {\n      values: values\n    }, dtype);\n  };\n\n  ArrayOps.multinomial = function (logits, numSamples, seed, normalized) {\n    if (normalized === void 0) {\n      normalized = false;\n    }\n\n    util.assertArgumentsAreTensors({\n      logits: logits\n    }, 'multinomial');\n    var numOutcomes = logits.size;\n    var origRank = logits.rank;\n\n    if (numOutcomes < 2) {\n      throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \" + (numOutcomes + \".\"));\n    }\n\n    if (origRank > 2) {\n      throw new Error(\"Rank of probabilities must be 1 or 2, but is \" + origRank);\n    }\n\n    seed = seed || Math.random();\n    var logits2D = origRank === 1 ? logits.as2D(1, -1) : logits;\n    var res = environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.multinomial(logits2D, normalized, numSamples, seed);\n    }, {\n      logits2D: logits2D\n    });\n    return origRank === 1 ? res.as1D() : res;\n  };\n\n  ArrayOps.oneHot = function (indices, depth, onValue, offValue) {\n    if (onValue === void 0) {\n      onValue = 1;\n    }\n\n    if (offValue === void 0) {\n      offValue = 0;\n    }\n\n    util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n\n    if (depth < 2) {\n      throw new Error(\"Error in oneHot: depth must be >=2, but it is \" + depth);\n    }\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.oneHot(indices, depth, onValue, offValue);\n    }, {\n      indices: indices\n    });\n  };\n\n  ArrayOps.fromPixels = function (pixels, numChannels) {\n    if (numChannels === void 0) {\n      numChannels = 3;\n    }\n\n    if (numChannels > 4) {\n      throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n\n    return environment_1.ENV.engine.fromPixels(pixels, numChannels);\n  };\n\n  ArrayOps.toPixels = function (img, canvas) {\n    return __awaiter(this, void 0, void 0, function () {\n      var _a, height, width, depth, min, max, data, multiplier, bytes, i, r, g, b, a, j, ctx, imageData;\n\n      return __generator(this, function (_b) {\n        switch (_b.label) {\n          case 0:\n            util.assertArgumentsAreTensors({\n              img: img\n            }, 'toPixels');\n\n            if (img.rank !== 2 && img.rank !== 3) {\n              throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \" + img.rank + \".\");\n            }\n\n            _a = img.shape.slice(0, 2), height = _a[0], width = _a[1];\n            depth = img.rank === 2 ? 1 : img.shape[2];\n\n            if (depth > 4 || depth === 2) {\n              throw new Error(\"toPixels only supports depth of size \" + (\"1, 3 or 4 but got \" + depth));\n            }\n\n            return [4, img.min().data()];\n\n          case 1:\n            min = _b.sent()[0];\n            return [4, img.max().data()];\n\n          case 2:\n            max = _b.sent()[0];\n\n            if (img.dtype === 'float32') {\n              if (min < 0 || max > 1) {\n                throw new Error(\"Tensor values for a float32 Tensor must be in the \" + (\"range [0 - 1] but got range [\" + min + \" - \" + max + \"].\"));\n              }\n            } else if (img.dtype === 'int32') {\n              if (min < 0 || max > 255) {\n                throw new Error(\"Tensor values for a int32 Tensor must be in the \" + (\"range [0 - 255] but got range [\" + min + \" - \" + max + \"].\"));\n              }\n            } else {\n              throw new Error(\"Unsupported type for toPixels: \" + img.dtype + \".\" + \" Please use float32 or int32 tensors.\");\n            }\n\n            return [4, img.data()];\n\n          case 3:\n            data = _b.sent();\n            multiplier = img.dtype === 'float32' ? 255 : 1;\n            bytes = new Uint8ClampedArray(width * height * 4);\n\n            for (i = 0; i < height * width; ++i) {\n              r = void 0, g = void 0, b = void 0, a = void 0;\n\n              if (depth === 1) {\n                r = data[i] * multiplier;\n                g = data[i] * multiplier;\n                b = data[i] * multiplier;\n                a = 255;\n              } else if (depth === 3) {\n                r = data[i * 3] * multiplier;\n                g = data[i * 3 + 1] * multiplier;\n                b = data[i * 3 + 2] * multiplier;\n                a = 255;\n              } else if (depth === 4) {\n                r = data[i * 4] * multiplier;\n                g = data[i * 4 + 1] * multiplier;\n                b = data[i * 4 + 2] * multiplier;\n                a = data[i * 4 + 3] * multiplier;\n              }\n\n              j = i * 4;\n              bytes[j + 0] = Math.round(r);\n              bytes[j + 1] = Math.round(g);\n              bytes[j + 2] = Math.round(b);\n              bytes[j + 3] = Math.round(a);\n            }\n\n            if (canvas != null) {\n              canvas.width = width;\n              canvas.height = height;\n              ctx = canvas.getContext('2d');\n              imageData = new ImageData(bytes, width, height);\n              ctx.putImageData(imageData, 0, 0);\n            }\n\n            return [2, bytes];\n        }\n      });\n    });\n  };\n\n  ArrayOps.reshape = function (_x, shape) {\n    util.assertArgumentsAreTensors({\n      x: _x\n    }, 'reshape');\n    shape = util.inferFromImplicitShape(shape, _x.size);\n    util.assert(_x.size === util.sizeFromShape(shape), 'new shape and old shape must have the same number of elements.');\n\n    var grad = function grad(dy) {\n      return {\n        x: function x() {\n          return dy.reshape(_x.shape);\n        }\n      };\n    };\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.reshape(_x, shape);\n    }, {\n      x: _x\n    }, grad);\n  };\n\n  ArrayOps.squeeze = function (x, axis) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'squeeze');\n    return ArrayOps.reshape(x, util.squeezeShape(x.shape, axis).newShape);\n  };\n\n  ArrayOps.cast = function (x, dtype) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'cast');\n\n    var grad = function grad(dy) {\n      return {\n        x: function x() {\n          return dy.clone();\n        }\n      };\n    };\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.cast(x, dtype);\n    }, {\n      x: x\n    }, grad);\n  };\n\n  ArrayOps.tile = function (x, reps) {\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'tile');\n    util.assert(x.rank === reps.length, \"Error in transpose: rank of input \" + x.rank + \" \" + (\"must match length of reps \" + reps + \".\"));\n\n    var grad = function grad(dy) {\n      var derX = function derX() {\n        var xGrad = ArrayOps.zerosLike(x);\n\n        if (x.rank === 1) {\n          for (var i = 0; i < reps[0]; ++i) {\n            xGrad = xGrad.add(dy.slice([i * x.shape[0]], [x.shape[0]]));\n          }\n        } else if (x.rank === 2) {\n          for (var i = 0; i < reps[0]; ++i) {\n            for (var j = 0; j < reps[1]; ++j) {\n              xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1]], [x.shape[0], x.shape[1]]));\n            }\n          }\n        } else if (x.rank === 3) {\n          for (var i = 0; i < reps[0]; ++i) {\n            for (var j = 0; j < reps[1]; ++j) {\n              for (var k = 0; k < reps[2]; ++k) {\n                xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));\n              }\n            }\n          }\n        } else if (x.rank === 4) {\n          for (var i = 0; i < reps[0]; ++i) {\n            for (var j = 0; j < reps[1]; ++j) {\n              for (var k = 0; k < reps[2]; ++k) {\n                for (var l = 0; l < reps[3]; ++l) {\n                  xGrad = xGrad.add(dy.slice([i * x.shape[0], j * x.shape[1], k * x.shape[2], l * x.shape[3]], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));\n                }\n              }\n            }\n          }\n        } else {\n          throw new Error(\"Gradient for tile operation is not implemented for rank-\" + (x.rank + \" tensors yet.\"));\n        }\n\n        return xGrad;\n      };\n\n      return {\n        x: derX\n      };\n    };\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.tile(x, reps);\n    }, {\n      x: x\n    }, grad);\n  };\n\n  ArrayOps.gather = function (x, indices, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    util.assertArgumentsAreTensors({\n      x: x,\n      indices: indices\n    }, 'gather');\n    util.assert(indices.dtype === 'int32', 'Indices must be of dtype `int32`');\n    var axes = axis_util_1.parseAxisParam(axis, x.shape);\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.gather(x, indices, axes[0]);\n    }, {\n      x: x,\n      indices: indices\n    });\n  };\n\n  ArrayOps.pad1d = function (x, paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    util.assert(paddings.length === 2, 'Invalid number of paddings. Must be length of 2.');\n    return ArrayOps.pad(x, [paddings], constantValue);\n  };\n\n  ArrayOps.pad2d = function (x, paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    util.assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  };\n\n  ArrayOps.pad3d = function (x, paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    util.assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  };\n\n  ArrayOps.pad4d = function (x, paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    util.assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, 'Invalid number of paddings. Must be length of 2 each.');\n    return ArrayOps.pad(x, paddings, constantValue);\n  };\n\n  ArrayOps.pad = function (_x2, paddings, constantValue) {\n    if (constantValue === void 0) {\n      constantValue = 0;\n    }\n\n    util.assertArgumentsAreTensors({\n      x: _x2\n    }, 'pad');\n\n    if (_x2.rank === 0) {\n      throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n\n    var begin = paddings.map(function (p) {\n      return p[0];\n    });\n\n    var grad = function grad(dy) {\n      return {\n        x: function x() {\n          return dy.slice(begin, _x2.shape);\n        }\n      };\n    };\n\n    return environment_1.ENV.engine.runKernel(function (backend) {\n      return backend.pad(_x2, paddings, constantValue);\n    }, {\n      x: _x2\n    }, grad);\n  };\n\n  ArrayOps.stack = function (tensors, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    util.assertArgumentsAreTensors({\n      tensors: tensors\n    }, 'stack');\n    util.assert(tensors.length >= 1, 'Pass at least one tensor to tf.stack');\n\n    if (tensors.length === 1) {\n      return tensors[0].expandDims(axis);\n    }\n\n    var rank = tensors[0].rank;\n    var shape = tensors[0].shape;\n    var dtype = tensors[0].dtype;\n    util.assert(axis <= rank, 'Axis must be <= rank of the tensor');\n    tensors.forEach(function (t) {\n      util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n    });\n    tensors.forEach(function (t) {\n      util.assert(dtype === t.dtype, 'All tensors passed to stack must have matching dtypes');\n    });\n    var expandedTensors = tensors.map(function (t) {\n      return t.expandDims(axis);\n    });\n    return concat_1.ConcatOps.concat(expandedTensors, axis);\n  };\n\n  ArrayOps.split = function (x, numOrSizeSplits, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'split');\n    axis = axis_util_1.parseAxisParam(axis, x.shape)[0];\n    var splitSizes;\n\n    if (typeof numOrSizeSplits === 'number') {\n      util.assert(x.shape[axis] % numOrSizeSplits === 0, 'Number of splits must evenly divide the axis.');\n      splitSizes = Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);\n    } else {\n      util.assert(x.shape[axis] === numOrSizeSplits.reduce(function (a, b) {\n        return a + b;\n      }), 'The sum of sizes must match the size of the axis dimension.');\n      splitSizes = numOrSizeSplits;\n    }\n\n    var begin = Array(x.rank).fill(0);\n    var size = x.shape.slice();\n    return splitSizes.map(function (s) {\n      size[axis] = s;\n      var slice = x.slice(begin, size);\n      begin[axis] += s;\n      return slice;\n    });\n  };\n\n  ArrayOps.expandDims = function (x, axis) {\n    if (axis === void 0) {\n      axis = 0;\n    }\n\n    util.assertArgumentsAreTensors({\n      x: x\n    }, 'expandDims');\n    util.assert(axis <= x.rank, 'Axis must be <= rank of the tensor');\n    var newShape = x.shape.slice();\n    newShape.splice(axis, 0, 1);\n    return ArrayOps.reshape(x, newShape);\n  };\n\n  ArrayOps.linspace = function (start, stop, num) {\n    if (num === 0) {\n      throw new Error('Cannot request zero samples');\n    }\n\n    var step = (stop - start) / (num - 1);\n    var values = makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n\n    for (var i = 1; i < values.length; i++) {\n      values[i] = values[i - 1] + step;\n    }\n\n    return ArrayOps.tensor1d(values, 'float32');\n  };\n\n  ArrayOps.range = function (start, stop, step, dtype) {\n    if (step === void 0) {\n      step = 1;\n    }\n\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    if (step === 0) {\n      throw new Error('Cannot have a step of zero');\n    }\n\n    var sameStartStop = start === stop;\n    var increasingRangeNegativeStep = start < stop && step < 0;\n    var decreasingRangePositiveStep = stop < start && step > 1;\n\n    if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n      return ArrayOps.zeros([0], dtype);\n    }\n\n    var numElements = Math.abs(Math.ceil((stop - start) / step));\n    var values = makeZerosTypedArray(numElements, dtype);\n\n    if (stop < start && step === 1) {\n      step = -1;\n    }\n\n    values[0] = start;\n\n    for (var i = 1; i < values.length; i++) {\n      values[i] = values[i - 1] + step;\n    }\n\n    return ArrayOps.tensor1d(values, dtype);\n  };\n\n  ArrayOps.buffer = function (shape, dtype, values) {\n    if (dtype === void 0) {\n      dtype = 'float32';\n    }\n\n    return new tensor_1.TensorBuffer(shape, dtype, values);\n  };\n\n  ArrayOps.print = function (x, verbose) {\n    if (verbose === void 0) {\n      verbose = false;\n    }\n\n    console.log(tensor_util.tensorToString(x, verbose));\n  };\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"tensor\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"scalar\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"tensor1d\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"tensor2d\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"tensor3d\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"tensor4d\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"ones\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"zeros\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"fill\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"onesLike\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"zerosLike\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"clone\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"randomNormal\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"truncatedNormal\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"randomUniform\", null);\n\n  __decorate([operation_1.operation], ArrayOps, \"rand\", null);\n\n  __decorate([operation_1.operation], ArrayOps, \"multinomial\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"oneHot\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  }), operation_1.operation], ArrayOps, \"fromPixels\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Visualization'\n  })], ArrayOps, \"toPixels\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Transformations'\n  }), operation_1.operation], ArrayOps, \"reshape\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Transformations'\n  })], ArrayOps, \"squeeze\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Transformations'\n  }), operation_1.operation], ArrayOps, \"cast\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Slicing and Joining'\n  }), operation_1.operation], ArrayOps, \"tile\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Slicing and Joining'\n  }), operation_1.operation], ArrayOps, \"gather\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Transformations'\n  }), operation_1.operation], ArrayOps, \"pad\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Slicing and Joining'\n  }), operation_1.operation], ArrayOps, \"stack\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Slicing and Joining'\n  }), operation_1.operation], ArrayOps, \"split\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Transformations'\n  }), operation_1.operation], ArrayOps, \"expandDims\", null);\n\n  __decorate([operation_1.operation, doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"linspace\", null);\n\n  __decorate([operation_1.operation, doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"range\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"buffer\", null);\n\n  __decorate([doc_1.doc({\n    heading: 'Tensors',\n    subheading: 'Creation'\n  })], ArrayOps, \"print\", null);\n\n  return ArrayOps;\n}();\n\nexports.ArrayOps = ArrayOps;\n\nfunction makeZerosTypedArray(size, dtype) {\n  if (dtype == null || dtype === 'float32') {\n    return new Float32Array(size);\n  } else if (dtype === 'int32') {\n    return new Int32Array(size);\n  } else if (dtype === 'bool') {\n    return new Uint8Array(size);\n  } else {\n    throw new Error(\"Unknown data type $ {dtype}\");\n  }\n}\n\nfunction makeOnesTypedArray(size, dtype) {\n  var array = makeZerosTypedArray(size, dtype);\n\n  for (var i = 0; i < array.length; i++) {\n    array[i] = 1;\n  }\n\n  return array;\n}\n\nfunction toTypedArray(a, dtype) {\n  if (noConversionNeeded(a, dtype)) {\n    return a;\n  }\n\n  if (Array.isArray(a)) {\n    a = util.flatten(a);\n  }\n\n  return util.copyTypedArray(a, dtype);\n}\n\nfunction noConversionNeeded(a, dtype) {\n  return a instanceof Float32Array && dtype === 'float32' || a instanceof Int32Array && dtype === 'int32' || a instanceof Uint8Array && dtype === 'bool';\n}","map":null,"metadata":{},"sourceType":"script"}