{"ast":null,"code":"\"use strict\";\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [0, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar seedrandom = require(\"seedrandom\");\n\nvar environment_1 = require(\"../environment\");\n\nvar axis_util = require(\"../ops/axis_util\");\n\nvar broadcast_util = require(\"../ops/broadcast_util\");\n\nvar concat_util = require(\"../ops/concat_util\");\n\nvar ops = require(\"../ops/ops\");\n\nvar ops_1 = require(\"../ops/ops\");\n\nvar selu_util = require(\"../ops/selu_util\");\n\nvar erf_util = require(\"../ops/erf_util\");\n\nvar tensor_1 = require(\"../tensor\");\n\nvar types = require(\"../types\");\n\nvar util = require(\"../util\");\n\nvar backend_util = require(\"./backend_util\");\n\nvar MathBackendCPU = function () {\n  function MathBackendCPU() {\n    this.data = new WeakMap();\n\n    if (typeof document !== 'undefined') {\n      this.canvas = document.createElement('canvas');\n    }\n  }\n\n  MathBackendCPU.prototype.register = function (dataId, shape, dtype) {\n    if (this.data.has(dataId)) {\n      throw new Error(\"Data buffer is already registered\");\n    }\n\n    this.data.set(dataId, null);\n  };\n\n  MathBackendCPU.prototype.write = function (dataId, values) {\n    if (values == null) {\n      throw new Error('MathBackendCPU.write(): values can not be null');\n    }\n\n    this.throwIfNoData(dataId);\n    this.data.set(dataId, values);\n  };\n\n  MathBackendCPU.prototype.fromPixels = function (pixels, numChannels) {\n    if (pixels == null) {\n      throw new Error('MathBackendCPU.writePixels(): pixels can not be null');\n    }\n\n    var vals;\n\n    if (pixels instanceof ImageData) {\n      vals = pixels.data;\n    } else if (pixels instanceof HTMLCanvasElement) {\n      vals = pixels.getContext('2d').getImageData(0, 0, pixels.width, pixels.height).data;\n    } else if (pixels instanceof HTMLImageElement || pixels instanceof HTMLVideoElement) {\n      if (this.canvas == null) {\n        throw new Error('Can\\'t read pixels from HTMLImageElement outside ' + 'the browser.');\n      }\n\n      this.canvas.width = pixels.width;\n      this.canvas.height = pixels.height;\n      this.canvas.getContext('2d').drawImage(pixels, 0, 0, pixels.width, pixels.height);\n      vals = this.canvas.getContext('2d').getImageData(0, 0, pixels.width, pixels.height).data;\n    } else {\n      throw new Error(\"pixels is of unknown type: \" + pixels.constructor.name);\n    }\n\n    var values;\n\n    if (numChannels === 4) {\n      values = new Int32Array(vals);\n    } else {\n      var numPixels = pixels.width * pixels.height;\n      values = new Int32Array(numPixels * numChannels);\n\n      for (var i = 0; i < numPixels; i++) {\n        for (var channel = 0; channel < numChannels; ++channel) {\n          values[i * numChannels + channel] = vals[i * 4 + channel];\n        }\n      }\n    }\n\n    var outShape = [pixels.height, pixels.width, numChannels];\n    return ops_1.tensor3d(values, outShape, 'int32');\n  };\n\n  MathBackendCPU.prototype.read = function (dataId) {\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (_a) {\n        return [2, this.readSync(dataId)];\n      });\n    });\n  };\n\n  MathBackendCPU.prototype.readSync = function (dataId) {\n    this.throwIfNoData(dataId);\n    return this.data.get(dataId);\n  };\n\n  MathBackendCPU.prototype.disposeData = function (dataId) {\n    if (this.data.has(dataId)) {\n      this.data.delete(dataId);\n    }\n  };\n\n  MathBackendCPU.prototype.time = function (f) {\n    return __awaiter(this, void 0, void 0, function () {\n      var start, kernelMs;\n      return __generator(this, function (_a) {\n        start = performance.now();\n        f();\n        kernelMs = performance.now() - start;\n        return [2, {\n          kernelMs: kernelMs\n        }];\n      });\n    });\n  };\n\n  MathBackendCPU.prototype.memory = function () {\n    return {\n      unreliable: true\n    };\n  };\n\n  MathBackendCPU.prototype.throwIfNoData = function (dataId) {\n    if (!this.data.has(dataId)) {\n      throw new Error(\"CPU backend: No data found for this tensor. \" + \"Did you change your backend in the middle of the program? \" + \"New backends can't use Tensors created with previous backends\");\n    }\n  };\n\n  MathBackendCPU.prototype.slice = function (x, begin, size) {\n    var buffer = ops.buffer(size, x.dtype);\n\n    for (var i = 0; i < buffer.size; ++i) {\n      var loc = buffer.indexToLoc(i);\n      var xLoc = loc.map(function (idx, j) {\n        return idx + begin[j];\n      });\n      buffer.set.apply(buffer, [x.get.apply(x, xLoc)].concat(loc));\n    }\n\n    return buffer.toTensor();\n  };\n\n  MathBackendCPU.prototype.reverse = function (x, axis) {\n    var buffer = ops.buffer(x.shape, x.dtype);\n    var xBuffer = x.buffer();\n\n    var _loop_1 = function _loop_1(i) {\n      var outLoc = buffer.indexToLoc(i);\n      var inLoc = outLoc.slice();\n      axis.forEach(function (ax) {\n        return inLoc[ax] = x.shape[ax] - 1 - inLoc[ax];\n      });\n      buffer.set.apply(buffer, [xBuffer.get.apply(xBuffer, inLoc)].concat(outLoc));\n    };\n\n    for (var i = 0; i < buffer.size; i++) {\n      _loop_1(i);\n    }\n\n    return buffer.toTensor();\n  };\n\n  MathBackendCPU.prototype.concat = function (a, b) {\n    var outShape = concat_util.computeOutShape(a.shape, b.shape, 1);\n    var buffer = ops.buffer(outShape, a.dtype);\n\n    if (a.shape[0] === 1 && b.shape[0] === 1) {\n      var aVals = a.dataSync();\n      var bVals = b.dataSync();\n      var vals = buffer.values;\n      vals.set(aVals, 0);\n      vals.set(bVals, a.size);\n      return buffer.toTensor();\n    }\n\n    for (var i = 0; i < outShape[0]; ++i) {\n      for (var j = 0; j < a.shape[1]; ++j) {\n        buffer.set(a.get(i, j), i, j);\n      }\n\n      for (var j = 0; j < b.shape[1]; ++j) {\n        buffer.set(b.get(i, j), i, j + a.shape[1]);\n      }\n    }\n\n    return buffer.toTensor();\n  };\n\n  MathBackendCPU.prototype.neg = function (x) {\n    return this.multiply(ops.scalar(-1), x);\n  };\n\n  MathBackendCPU.prototype.add = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) {\n      return aValue + bValue;\n    });\n  };\n\n  MathBackendCPU.prototype.subtract = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) {\n      return aValue - bValue;\n    });\n  };\n\n  MathBackendCPU.prototype.pow = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) {\n      return Math.pow(aValue, bValue);\n    });\n  };\n\n  MathBackendCPU.prototype.matMul = function (a, b, transposeA, transposeB) {\n    var sharedDim = transposeA ? a.shape[0] : a.shape[1];\n    var leftDim = transposeA ? a.shape[1] : a.shape[0];\n    var rightDim = transposeB ? b.shape[0] : b.shape[1];\n    var aValues = a.dataSync();\n    var bValues = b.dataSync();\n\n    var _a = transposeA ? [1, a.strides[0]] : [a.strides[0], 1],\n        aOuterStep = _a[0],\n        aInnerStep = _a[1];\n\n    var _b = transposeB ? [b.strides[0], 1] : [1, b.strides[0]],\n        bOuterStep = _b[0],\n        bInnerStep = _b[1];\n\n    var aOuterEnd = leftDim * aOuterStep;\n    var bOuterEnd = rightDim * bOuterStep;\n    var result = new Float32Array(leftDim * rightDim);\n    var resultIndex = 0;\n\n    for (var aOuter = 0; aOuter < aOuterEnd; aOuter += aOuterStep) {\n      for (var bOuter = 0; bOuter < bOuterEnd; bOuter += bOuterStep) {\n        var aInner = aOuter;\n        var bInner = bOuter;\n        var sum = 0;\n\n        for (var k = 0; k < sharedDim; ++k) {\n          sum += aValues[aInner] * bValues[bInner];\n          aInner += aInnerStep;\n          bInner += bInnerStep;\n        }\n\n        result[resultIndex++] = sum;\n      }\n    }\n\n    return ops.tensor2d(result, [leftDim, rightDim]);\n  };\n\n  MathBackendCPU.prototype.multiply = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) {\n      return aValue * bValue;\n    });\n  };\n\n  MathBackendCPU.prototype.divide = function (a, b) {\n    var op;\n    var outputDtype;\n\n    if (a.dtype === 'int32' && b.dtype === 'int32') {\n      outputDtype = 'int32';\n\n      op = function op(a, b) {\n        return Math.floor(a / b);\n      };\n    } else {\n      outputDtype = 'float32';\n\n      op = function op(a, b) {\n        return a / b;\n      };\n    }\n\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  };\n\n  MathBackendCPU.prototype.sum = function (x, axes) {\n    axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n\n    var _a = axis_util.computeOutAndReduceShapes(x.shape, axes),\n        outShape = _a[0],\n        reduceShape = _a[1];\n\n    var resultDtype = types.upcastType(x.dtype, 'int32');\n    var result = ops.zeros(outShape, resultDtype);\n    var reduceSize = util.sizeFromShape(reduceShape);\n    var vals = result.dataSync();\n    var aVals = x.dataSync();\n\n    for (var i = 0; i < vals.length; ++i) {\n      var offset = i * reduceSize;\n      var sum = 0;\n\n      for (var j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n\n      vals[i] = sum;\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.argMin = function (x, axis) {\n    var axes = [axis];\n    axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n\n    var _a = axis_util.computeOutAndReduceShapes(x.shape, axes),\n        outShape = _a[0],\n        reduceShape = _a[1];\n\n    var result = ops.zeros(outShape, 'int32');\n    var reduceSize = util.sizeFromShape(reduceShape);\n    var vals = result.dataSync();\n    var aVals = x.dataSync();\n\n    for (var i = 0; i < vals.length; ++i) {\n      var offset = i * reduceSize;\n      var min = aVals[offset];\n      var minIndex = 0;\n\n      for (var j = 0; j < reduceSize; ++j) {\n        var value = aVals[offset + j];\n\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n\n      vals[i] = minIndex;\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.argMax = function (x, axis) {\n    var axes = [axis];\n    axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n\n    var _a = axis_util.computeOutAndReduceShapes(x.shape, axes),\n        outShape = _a[0],\n        reduceShape = _a[1];\n\n    var result = ops.zeros(outShape, 'int32');\n    var reduceSize = util.sizeFromShape(reduceShape);\n    var vals = result.dataSync();\n    var aVals = x.dataSync();\n\n    for (var i = 0; i < vals.length; ++i) {\n      var offset = i * reduceSize;\n      var max = aVals[offset];\n      var maxIndex = 0;\n\n      for (var j = 0; j < reduceSize; ++j) {\n        var value = aVals[offset + j];\n\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n\n      vals[i] = maxIndex;\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.equal = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal === bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.notEqual = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal !== bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.less = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal < bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.lessEqual = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal <= bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.greater = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal > bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.greaterEqual = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal >= bVal ? 1 : 0;\n    });\n  };\n\n  MathBackendCPU.prototype.logicalNot = function (x) {\n    var values = x.dataSync();\n    var newValues = new Int32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = values[i] ? 0 : 1;\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    }, 'bool');\n  };\n\n  MathBackendCPU.prototype.logicalAnd = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal && bVal;\n    });\n  };\n\n  MathBackendCPU.prototype.logicalOr = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n      return aVal || bVal;\n    });\n  };\n\n  MathBackendCPU.prototype.where = function (condition, a, b, dtype) {\n    var values = condition.dataSync();\n    var aValues = a.dataSync();\n    var bValues = b.dataSync();\n    var result = ops.zeros(a.shape, dtype);\n    var newValues = result.dataSync();\n    var index = 0;\n    var offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ? 1 : a.shape[1];\n\n    for (var i = 0; i < values.length; i++) {\n      for (var j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.topKValues = function (x, k) {\n    return this.topK(x, k).values;\n  };\n\n  MathBackendCPU.prototype.topKIndices = function (x, k) {\n    return this.topK(x, k).indices;\n  };\n\n  MathBackendCPU.prototype.topK = function (x, k) {\n    var values = x.dataSync();\n    var valuesAndIndices = [];\n\n    for (var i = 0; i < values.length; i++) {\n      valuesAndIndices.push({\n        value: values[i],\n        index: i\n      });\n    }\n\n    valuesAndIndices.sort(function (a, b) {\n      return b.value - a.value;\n    });\n    var topkValues = util.getTypedArrayFromDType(x.dtype, k);\n    var topkIndices = new Int32Array(k);\n\n    for (var i = 0; i < k; i++) {\n      topkValues[i] = valuesAndIndices[i].value;\n      topkIndices[i] = valuesAndIndices[i].index;\n    }\n\n    return {\n      values: ops.tensor1d(topkValues, x.dtype),\n      indices: ops.tensor1d(topkIndices, 'int32')\n    };\n  };\n\n  MathBackendCPU.prototype.min = function (x, axes) {\n    axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n\n    var _a = axis_util.computeOutAndReduceShapes(x.shape, axes),\n        outShape = _a[0],\n        reduceShape = _a[1];\n\n    var result = ops.zeros(outShape, x.dtype);\n    var reduceSize = util.sizeFromShape(reduceShape);\n    var vals = result.dataSync();\n    var aVals = x.dataSync();\n\n    for (var i = 0; i < vals.length; ++i) {\n      var offset = i * reduceSize;\n      var min = aVals[0];\n\n      for (var j = 0; j < reduceSize; ++j) {\n        var value = aVals[offset + j];\n\n        if (value < min) {\n          min = value;\n        }\n      }\n\n      vals[i] = min;\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.minimum = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n      return Math.min(aVal, bVal);\n    });\n  };\n\n  MathBackendCPU.prototype.mod = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n      var rem = aVal % bVal;\n\n      if (aVal < 0 && bVal < 0 || aVal >= 0 && bVal >= 0) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  };\n\n  MathBackendCPU.prototype.max = function (x, axes) {\n    axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n\n    var _a = axis_util.computeOutAndReduceShapes(x.shape, axes),\n        outShape = _a[0],\n        reduceShape = _a[1];\n\n    var result = ops.zeros(outShape, x.dtype);\n    var reduceSize = util.sizeFromShape(reduceShape);\n    var vals = result.dataSync();\n    var aVals = x.dataSync();\n\n    for (var i = 0; i < vals.length; ++i) {\n      var offset = i * reduceSize;\n      var max = aVals[offset];\n\n      for (var j = 0; j < reduceSize; ++j) {\n        var value = aVals[offset + j];\n\n        if (value > max) {\n          max = value;\n        }\n      }\n\n      vals[i] = max;\n    }\n\n    return result;\n  };\n\n  MathBackendCPU.prototype.maximum = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n      return Math.max(aVal, bVal);\n    });\n  };\n\n  MathBackendCPU.prototype.squaredDifference = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n      var diff = aVal - bVal;\n      return diff * diff;\n    });\n  };\n\n  MathBackendCPU.prototype.ceil = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = Math.ceil(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.floor = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = Math.floor(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.sign = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      if (values[i] < 0) {\n        newValues[i] = -1;\n      } else if (values[i] > 0) {\n        newValues[i] = 1;\n      } else {\n        newValues[i] = 0;\n      }\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.round = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var base = Math.floor(values[i]);\n\n      if (values[i] - base < 0.5) {\n        newValues[i] = Math.floor(values[i]);\n      } else if (values[i] - base > 0.5) {\n        newValues[i] = Math.ceil(values[i]);\n      } else {\n        if (base % 2.0 === 0.0) {\n          newValues[i] = base;\n        } else {\n          newValues[i] = base + 1.0;\n        }\n      }\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.exp = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = Math.exp(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.expm1 = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = Math.expm1(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.log = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n      newValues[i] = Math.log(value);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.log1p = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n      newValues[i] = Math.log1p(value);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.sqrt = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n      newValues[i] = Math.sqrt(value);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.rsqrt = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n      newValues[i] = 1 / Math.sqrt(value);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.square = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n      newValues[i] = value * value;\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.reciprocal = function (x) {\n    var values = x.dataSync();\n    var newValues = new Float32Array(values.length);\n\n    for (var i = 0; i < values.length; ++i) {\n      newValues[i] = 1 / values[i];\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: newValues\n    });\n  };\n\n  MathBackendCPU.prototype.relu = function (x) {\n    var res = ops.zeros(x.shape, x.dtype);\n    var resVals = res.dataSync();\n    var inVals = x.dataSync();\n\n    for (var i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n\n    return res;\n  };\n\n  MathBackendCPU.prototype.elu = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      var v = values[i];\n\n      if (v >= 0) {\n        resultValues[i] = v;\n      } else {\n        resultValues[i] = Math.exp(v) - 1;\n      }\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.eluDer = function (dy, y) {\n    var resultValues = new Float32Array(y.size);\n    var values = y.dataSync();\n    var dyValues = dy.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      var v = values[i];\n\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n\n    return tensor_1.Tensor.make(y.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.selu = function (x) {\n    var scaleAlpha = selu_util.SELU_SCALEALPHA;\n    var scale = selu_util.SELU_SCALE;\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      var v = values[i];\n\n      if (v >= 0) {\n        resultValues[i] = scale * v;\n      } else {\n        resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n      }\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.clip = function (x, min, max) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.min(max, Math.max(min, values[i]));\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.abs = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.abs(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.int = function (x) {\n    var resultValues = new Int32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = values[i];\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    }, 'int32');\n  };\n\n  MathBackendCPU.prototype.sigmoid = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.softplus = function (x) {\n    var epsilon = 1.1920928955078125e-7;\n    var threshold = Math.log(epsilon) + 2.0;\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      var tooLarge = values[i] > -threshold;\n      var tooSmall = values[i] < threshold;\n      var expX = Math.exp(values[i]);\n      var result = void 0;\n\n      if (tooSmall) {\n        result = expX;\n      } else if (tooLarge) {\n        result = values[i];\n      } else {\n        result = Math.log(1.0 + expX);\n      }\n\n      resultValues[i] = result;\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.sin = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sin(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.cos = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cos(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.tan = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.tan(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.asin = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asin(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.acos = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acos(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.atan = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atan(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.atan2 = function (a, b) {\n    return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) {\n      return Math.atan2(aValue, bValue);\n    });\n  };\n\n  MathBackendCPU.prototype.sinh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.sinh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.cosh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.cosh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.tanh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = util.tanh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.asinh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.asinh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.acosh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.acosh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.atanh = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      resultValues[i] = Math.atanh(values[i]);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.erf = function (x) {\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n    var p = erf_util.ERF_P;\n    var a1 = erf_util.ERF_A1;\n    var a2 = erf_util.ERF_A2;\n    var a3 = erf_util.ERF_A3;\n    var a4 = erf_util.ERF_A4;\n    var a5 = erf_util.ERF_A5;\n\n    for (var i = 0; i < values.length; ++i) {\n      var v = values[i];\n      var t = 1.0 / (1.0 + p * v);\n      resultValues[i] = 1.0 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-v * v);\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.step = function (x, alpha) {\n    if (alpha === void 0) {\n      alpha = 0;\n    }\n\n    var resultValues = new Float32Array(x.size);\n    var values = x.dataSync();\n\n    for (var i = 0; i < values.length; ++i) {\n      var value = values[i];\n\n      if (isNaN(value)) {\n        resultValues[i] = NaN;\n      } else {\n        resultValues[i] = value > 0 ? 1 : alpha;\n      }\n    }\n\n    return tensor_1.Tensor.make(x.shape, {\n      values: resultValues\n    });\n  };\n\n  MathBackendCPU.prototype.conv2d = function (x, filter, convInfo) {\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var padLeft = convInfo.padInfo.left;\n    var padTop = convInfo.padInfo.top;\n    var y = ops.buffer(convInfo.outShape, x.dtype);\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n          var xRCorner = yR * convInfo.strideHeight - padLeft;\n\n          for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n            var xCCorner = yC * convInfo.strideWidth - padTop;\n            var dotProd = 0;\n\n            for (var wR = 0; wR < filterHeight; wR++) {\n              var xR = xRCorner + wR * dilationHeight;\n\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n\n              for (var wC = 0; wC < filterWidth; wC++) {\n                var xC = xCCorner + wC * dilationWidth;\n\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  var pixel = x.get(b, xR, xC, d1);\n                  var weight = filter.get(wR, wC, d1, d2);\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n\n            y.set(dotProd, b, yR, yC, d2);\n          }\n        }\n      }\n    }\n\n    return y.toTensor();\n  };\n\n  MathBackendCPU.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var topPad = filterHeight - 1 - convInfo.padInfo.top;\n    var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var dx = ops.buffer(convInfo.inShape, 'float32');\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (var xR = 0; xR < convInfo.inHeight; ++xR) {\n          var xRCorner = xR - leftPad;\n          var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          var yRMax = Math.min(convInfo.outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (var xC = 0; xC < convInfo.inWidth; ++xC) {\n            var xCCorner = xC - topPad;\n            var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            var yCMax = Math.min(convInfo.outWidth, (filterWidth + xCCorner) / strideWidth);\n            var dotProd = 0;\n\n            for (var yR = xRMin; yR < yRMax; ++yR) {\n              var wR = yR * strideHeight - xRCorner;\n\n              for (var yC = xCMin; yC < yCMax; ++yC) {\n                var wC = yC * strideWidth - xCCorner;\n\n                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                  var pixel = dy.get(b, yR, yC, d2);\n                  var weight = filter.get(filterHeight - 1 - wR, filterWidth - 1 - wC, d1, d2);\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n\n            dx.set(dotProd, b, xR, xC, d1);\n          }\n        }\n      }\n    }\n\n    return dx.toTensor();\n  };\n\n  MathBackendCPU.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dW = ops.buffer(convInfo.filterShape, 'float32');\n    var leftPad = convInfo.padInfo.left;\n    var topPad = convInfo.padInfo.top;\n\n    for (var wR = 0; wR < filterHeight; ++wR) {\n      var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (var wC = 0; wC < filterWidth; ++wC) {\n        var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            var dotProd = 0;\n\n            for (var b = 0; b < convInfo.batchSize; ++b) {\n              for (var yR = yRMin; yR < yRMax; ++yR) {\n                var xR = wR + yR * strideHeight - topPad;\n\n                for (var yC = yCMin; yC < yCMax; ++yC) {\n                  var xC = wC + yC * strideWidth - leftPad;\n                  dotProd += x.get(b, xR, xC, d1) * dy.get(b, yR, yC, d2);\n                }\n              }\n            }\n\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n\n    return dW.toTensor();\n  };\n\n  MathBackendCPU.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var dilationHeight = convInfo.dilationHeight;\n    var dilationWidth = convInfo.dilationWidth;\n    var padLeft = convInfo.padInfo.left;\n    var padTop = convInfo.padInfo.top;\n    var chMul = convInfo.outChannels / convInfo.inChannels;\n    var y = ops.buffer(convInfo.outShape, x.dtype);\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n          var xRCorner = yR * convInfo.strideHeight - padLeft;\n\n          for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n            var xCCorner = yC * convInfo.strideWidth - padTop;\n\n            for (var q = 0; q < chMul; ++q) {\n              var dotProd = 0;\n\n              for (var wR = 0; wR < filterHeight; ++wR) {\n                var xR = xRCorner + wR * dilationHeight;\n\n                if (xR < 0 || xR >= convInfo.inHeight) {\n                  continue;\n                }\n\n                for (var wC = 0; wC < filterWidth; ++wC) {\n                  var xC = xCCorner + wC * dilationWidth;\n\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n\n                  var pixel = x.get(b, xR, xC, d1);\n                  var weight = filter.get(wR, wC, d1, q);\n                  dotProd += pixel * weight;\n                }\n              }\n\n              y.set(dotProd, b, yR, yC, d1 * chMul + q);\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor();\n  };\n\n  MathBackendCPU.prototype.tile = function (x, reps) {\n    var newShape = new Array(x.rank);\n\n    for (var i = 0; i < newShape.length; i++) {\n      newShape[i] = x.shape[i] * reps[i];\n    }\n\n    var result = ops.buffer(newShape, x.dtype);\n    var xBuf = x.buffer();\n\n    for (var i = 0; i < result.values.length; ++i) {\n      var newLoc = result.indexToLoc(i);\n      var originalLoc = new Array(x.rank);\n\n      for (var i_1 = 0; i_1 < originalLoc.length; i_1++) {\n        originalLoc[i_1] = newLoc[i_1] % x.shape[i_1];\n      }\n\n      var originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n\n    return result.toTensor();\n  };\n\n  MathBackendCPU.prototype.pad = function (x, paddings, constantValue) {\n    var outShape = paddings.map(function (p, i) {\n      return p[0] + x.shape[i] + p[1];\n    });\n    var start = paddings.map(function (p) {\n      return p[0];\n    });\n    var xBuffer = x.buffer();\n    var buffer = ops.buffer(outShape, x.dtype);\n\n    if (constantValue !== 0) {\n      buffer.values.fill(constantValue);\n    }\n\n    for (var i = 0; i < x.size; i++) {\n      var coords = xBuffer.indexToLoc(i);\n      var outCoords = coords.map(function (c, i) {\n        return c + start[i];\n      });\n      buffer.set.apply(buffer, [x.get.apply(x, coords)].concat(outCoords));\n    }\n\n    return buffer.toTensor();\n  };\n\n  MathBackendCPU.prototype.transpose = function (x, perm) {\n    var newShape = new Array(x.rank);\n\n    for (var i = 0; i < newShape.length; i++) {\n      newShape[i] = x.shape[perm[i]];\n    }\n\n    var values = x.dataSync();\n    var result = ops_1.buffer(newShape, x.dtype);\n    var xBuf = x.buffer();\n\n    for (var i = 0; i < x.size; ++i) {\n      var loc = xBuf.indexToLoc(i);\n      var newLoc = new Array(loc.length);\n\n      for (var i_2 = 0; i_2 < newLoc.length; i_2++) {\n        newLoc[i_2] = loc[perm[i_2]];\n      }\n\n      var newIndex = result.locToIndex(newLoc);\n      result.values[newIndex] = values[i];\n    }\n\n    return result.toTensor();\n  };\n\n  MathBackendCPU.prototype.gather = function (x, indices, axis) {\n    var newShape = x.shape.slice();\n    var indicesValues = indices.dataSync();\n    newShape[axis] = indicesValues.length;\n    var result = ops_1.buffer(newShape, x.dtype);\n    var xBuf = x.buffer();\n\n    for (var i = 0; i < result.size; ++i) {\n      var newLoc = result.indexToLoc(i);\n      var originalLoc = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n      var originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n\n    return result.toTensor();\n  };\n\n  MathBackendCPU.prototype.pool = function (x, convInfo, poolType) {\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var y = ops.buffer(convInfo.outShape, 'float32');\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d = 0; d < convInfo.inChannels; ++d) {\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n          var xRCorner = yR * strideHeight - padTop;\n          var xRMin = Math.max(0, xRCorner);\n          var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n\n          for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n            var xCCorner = yC * strideWidth - padLeft;\n            var xCMin = Math.max(0, xCCorner);\n            var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n            var minMaxValue = poolType === 'max' ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;\n            var avgValue = 0;\n            var count = 0;\n\n            for (var xR = xRMin; xR < xRMax; ++xR) {\n              for (var xC = xCMin; xC < xCMax; ++xC) {\n                var pixel = x.get(b, xR, xC, d);\n\n                if (poolType === 'max' && pixel > minMaxValue) {\n                  minMaxValue = pixel;\n                } else if (poolType === 'avg') {\n                  avgValue += pixel;\n                  count++;\n                }\n              }\n\n              if (isNaN(minMaxValue)) {\n                break;\n              }\n            }\n\n            y.set(poolType === 'avg' ? avgValue / count : minMaxValue, b, yR, yC, d);\n          }\n        }\n      }\n    }\n\n    return y.toTensor();\n  };\n\n  MathBackendCPU.prototype.maxPool = function (x, convInfo) {\n    return this.pool(x, convInfo, 'max');\n  };\n\n  MathBackendCPU.prototype.maxPoolPositions = function (x, convInfo) {\n    var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var padTop = convInfo.padInfo.top;\n    var padLeft = convInfo.padInfo.left;\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d = 0; d < convInfo.inChannels; ++d) {\n        for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n          var xRCorner = yR * strideHeight - padTop;\n          var xRMin = Math.max(0, xRCorner);\n          var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n\n          for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n            var xCCorner = yC * strideWidth - padLeft;\n            var xCMin = Math.max(0, xCCorner);\n            var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n            var maxValue = Number.NEGATIVE_INFINITY;\n            var maxPosition = -1;\n\n            for (var xR = xRMin; xR < xRMax; ++xR) {\n              var wR = xR - xRCorner;\n\n              for (var xC = xCMin; xC < xCMax; ++xC) {\n                var wC = xC - xCCorner;\n                var pixel = x.get(b, xR, xC, d);\n\n                if (pixel > maxValue) {\n                  maxValue = pixel;\n                  maxPosition = wR * filterWidth + wC;\n                }\n              }\n            }\n\n            maxPositions.set(maxPosition, b, yR, yC, d);\n          }\n        }\n      }\n    }\n\n    return maxPositions.toTensor();\n  };\n\n  MathBackendCPU.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n    var maxPositions = this.maxPoolPositions(x, convInfo);\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n    var padTop = filterHeight - 1 - convInfo.padInfo.top;\n    var dx = ops.buffer(x.shape, 'float32');\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d = 0; d < convInfo.inChannels; ++d) {\n        for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            var dyRCorner = dxR - padTop;\n            var dyCCorner = dxC - padLeft;\n            var dotProd = 0;\n\n            for (var wR = 0; wR < filterHeight; ++wR) {\n              var dyR = (dyRCorner + wR) / strideHeight;\n\n              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {\n                continue;\n              }\n\n              for (var wC = 0; wC < filterWidth; ++wC) {\n                var dyC = (dyCCorner + wC) / strideWidth;\n\n                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n\n                var maxPos = filterHeight * filterWidth - 1 - maxPositions.get(b, dyR, dyC, d);\n                var curPos = wR * filterWidth + wC;\n                var mask = maxPos === curPos ? 1 : 0;\n\n                if (mask === 0) {\n                  continue;\n                }\n\n                var pixel = dy.get(b, dyR, dyC, d);\n                dotProd += pixel * mask;\n              }\n            }\n\n            dx.set(dotProd, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n\n    return dx.toTensor();\n  };\n\n  MathBackendCPU.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n    var strideHeight = convInfo.strideHeight;\n    var strideWidth = convInfo.strideWidth;\n    var filterHeight = convInfo.filterHeight;\n    var filterWidth = convInfo.filterWidth;\n    var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n    var padTop = filterHeight - 1 - convInfo.padInfo.top;\n    var dx = ops.buffer(x.shape, 'float32');\n    var avgMultiplier = 1 / (filterHeight * filterWidth);\n\n    for (var b = 0; b < convInfo.batchSize; ++b) {\n      for (var d = 0; d < convInfo.inChannels; ++d) {\n        for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n          for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n            var dyRCorner = dxR - padTop;\n            var dyCCorner = dxC - padLeft;\n            var dotProd = 0;\n\n            for (var wR = 0; wR < filterHeight; ++wR) {\n              var dyR = (dyRCorner + wR) / strideHeight;\n\n              if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {\n                continue;\n              }\n\n              for (var wC = 0; wC < filterWidth; ++wC) {\n                var dyC = (dyCCorner + wC) / strideWidth;\n\n                if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {\n                  continue;\n                }\n\n                var pixel = dy.get(b, dyR, dyC, d);\n                dotProd += pixel;\n              }\n            }\n\n            dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n          }\n        }\n      }\n    }\n\n    return dx.toTensor();\n  };\n\n  MathBackendCPU.prototype.cast = function (x, dtype) {\n    return backend_util.castTensor(x, dtype, this);\n  };\n\n  MathBackendCPU.prototype.reshape = function (x, shape) {\n    return backend_util.reshapeTensor(x, shape);\n  };\n\n  MathBackendCPU.prototype.avgPool = function (x, convInfo) {\n    return this.pool(x, convInfo, 'avg').toFloat();\n  };\n\n  MathBackendCPU.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n    var _a = x.shape,\n        batch = _a[0],\n        oldHeight = _a[1],\n        oldWidth = _a[2],\n        numChannels = _a[3];\n    var output = ops.buffer([batch, newHeight, newWidth, numChannels], x.dtype);\n    var effectiveInputSize = alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n    var effectiveOutputSize = alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n\n    for (var b = 0; b < batch; b++) {\n      for (var r = 0; r < newHeight; r++) {\n        for (var c = 0; c < newWidth; c++) {\n          for (var d = 0; d < numChannels; d++) {\n            var sourceFracRow = effectiveInputSize[0] * r / effectiveOutputSize[0];\n            var sourceFracCol = effectiveInputSize[1] * c / effectiveOutputSize[1];\n            var sourceRowFloor = Math.floor(sourceFracRow);\n            var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n            var sourceColFloor = Math.floor(sourceFracCol);\n            var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n            var topLeft = x.get(b, sourceRowFloor, sourceColFloor, d);\n            var bottomLeft = x.get(b, sourceRowCeil, sourceColFloor, d);\n            var topRight = x.get(b, sourceRowFloor, sourceColCeil, d);\n            var bottomRight = x.get(b, sourceRowCeil, sourceColCeil, d);\n            var rowFrac = sourceFracRow - sourceRowFloor;\n            var colFrac = sourceFracCol - sourceColFloor;\n            var top_1 = topLeft + (topRight - topLeft) * colFrac;\n            var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            var newValue = top_1 + (bottom - top_1) * rowFrac;\n            output.set(newValue, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  };\n\n  MathBackendCPU.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n    var _a = x.shape,\n        batch = _a[0],\n        oldHeight = _a[1],\n        oldWidth = _a[2],\n        numChannels = _a[3];\n    var output = ops.buffer([batch, newHeight, newWidth, numChannels], x.dtype);\n    var effectiveInputSize = alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n    var effectiveOutputSize = alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n\n    for (var b = 0; b < batch; b++) {\n      for (var r = 0; r < newHeight; r++) {\n        for (var c = 0; c < newWidth; c++) {\n          for (var d = 0; d < numChannels; d++) {\n            var sourceFracRow = effectiveInputSize[0] * r / effectiveOutputSize[0];\n            var sourceFracCol = effectiveInputSize[1] * c / effectiveOutputSize[1];\n            var sourceNearestRow = Math.min(oldHeight - 1, Math.round(sourceFracRow));\n            var sourceNearestCol = Math.min(oldWidth - 1, Math.round(sourceFracCol));\n            var newValue = x.get(b, sourceNearestRow, sourceNearestCol, d);\n            output.set(newValue, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  };\n\n  MathBackendCPU.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n    var xValues = x.dataSync();\n    var meanValues = mean.dataSync();\n    var varianceValues = variance.dataSync();\n    var scaleValues = scale ? scale.dataSync() : new Float32Array([1]);\n    var offsetValues = offset ? offset.dataSync() : new Float32Array([0]);\n    var outValues = new Float32Array(xValues.length);\n\n    for (var i = 0; i < xValues.length; i++) {\n      outValues[i] = offsetValues[i % offsetValues.length] + (xValues[i] - meanValues[i % meanValues.length]) * scaleValues[i % scaleValues.length] / Math.sqrt(varianceValues[i % varianceValues.length] + varianceEpsilon);\n    }\n\n    return ops_1.tensor4d(outValues, x.shape);\n  };\n\n  MathBackendCPU.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n    var output = ops.buffer(x.shape, 'float32');\n    var rad = radius;\n    var maxD = output.shape[3] - 1;\n\n    function sumAcrossChannels(b, r, c, d) {\n      var sum = 0.0;\n\n      for (var j = Math.max(0, d - rad); j <= Math.min(d + rad, maxD); j++) {\n        var z = x.get(b, r, c, j);\n        sum += z * z;\n      }\n\n      return sum;\n    }\n\n    for (var b = 0; b < output.shape[0]; b++) {\n      for (var r = 0; r <= output.shape[1]; r++) {\n        for (var c = 0; c < output.shape[2]; c++) {\n          for (var d = 0; d < output.shape[3]; d++) {\n            var sum = sumAcrossChannels(b, r, c, d);\n            var val = x.get(b, r, c, d) * Math.pow(bias + alpha * sum, -beta);\n            output.set(val, b, r, c, d);\n          }\n        }\n      }\n    }\n\n    return output.toTensor();\n  };\n\n  MathBackendCPU.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n    var probabilities = normalized ? logits : ops.softmax(logits);\n    var batchSize = probabilities.shape[0];\n    var numEvents = probabilities.shape[1];\n    var res = ops.zeros([batchSize, numSamples], 'int32');\n    var resVals = res.dataSync();\n    var probVals = probabilities.dataSync();\n\n    for (var b = 0; b < batchSize; ++b) {\n      var offset = b * numEvents;\n      var cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n\n      for (var event_1 = 1; event_1 < cdf.length; ++event_1) {\n        cdf[event_1] = cdf[event_1 - 1] + probVals[offset + event_1];\n      }\n\n      var random = seedrandom.alea(seed.toString());\n      var outOffset = b * numSamples;\n\n      for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n        var r = random();\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (var event_2 = 0; event_2 < cdf.length; event_2++) {\n          if (r < cdf[event_2]) {\n            resVals[outOffset + sampleId] = event_2;\n            break;\n          }\n        }\n      }\n    }\n\n    return res;\n  };\n\n  MathBackendCPU.prototype.oneHot = function (indices, depth, onValue, offValue) {\n    var res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n\n    for (var event_3 = 0; event_3 < indices.size; ++event_3) {\n      res[event_3 * depth + indices.get(event_3)] = onValue;\n    }\n\n    return ops.tensor2d(res, [indices.size, depth]);\n  };\n\n  MathBackendCPU.prototype.broadcastedBinaryOp = function (a, b, dtype, op) {\n    var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    var result = ops.buffer(newShape, dtype);\n    var aValues = a.dataSync();\n    var bValues = b.dataSync();\n    var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n    var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n    var aBuf = a.buffer();\n    var bBuf = b.buffer();\n\n    var _loop_2 = function _loop_2(i) {\n      var loc = result.indexToLoc(i);\n      var aLoc = loc.slice(-a.rank);\n      aBroadcastDims.forEach(function (d) {\n        return aLoc[d] = 0;\n      });\n      var aIndex = aBuf.locToIndex(aLoc);\n      var bLoc = loc.slice(-b.rank);\n      bBroadcastDims.forEach(function (d) {\n        return bLoc[d] = 0;\n      });\n      var bIndex = bBuf.locToIndex(bLoc);\n      result.values[i] = op(aValues[aIndex], bValues[bIndex]);\n    };\n\n    for (var i = 0; i < result.values.length; ++i) {\n      _loop_2(i);\n    }\n\n    return result.toTensor();\n  };\n\n  MathBackendCPU.prototype.dispose = function () {};\n\n  return MathBackendCPU;\n}();\n\nexports.MathBackendCPU = MathBackendCPU;\nenvironment_1.ENV.registerBackend('cpu', function () {\n  return new MathBackendCPU();\n}, 1);","map":null,"metadata":{},"sourceType":"script"}