{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = Object.setPrototypeOf || {\n    __proto__: []\n  } instanceof Array && function (d, b) {\n    d.__proto__ = b;\n  } || function (d, b) {\n    for (var p in b) {\n      if (b.hasOwnProperty(p)) d[p] = b[p];\n    }\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\n\nvar activations_1 = require(\"../activations\");\n\nvar K = require(\"../backend/tfjs_backend\");\n\nvar common_1 = require(\"../common\");\n\nvar constraints_1 = require(\"../constraints\");\n\nvar topology_1 = require(\"../engine/topology\");\n\nvar errors_1 = require(\"../errors\");\n\nvar initializers_1 = require(\"../initializers\");\n\nvar regularizers_1 = require(\"../regularizers\");\n\nvar types_1 = require(\"../types\");\n\nvar conv_utils_1 = require(\"../utils/conv_utils\");\n\nvar generic_utils = require(\"../utils/generic_utils\");\n\nvar Conv = function (_super) {\n  __extends(Conv, _super);\n\n  function Conv(rank, config) {\n    var _this = _super.call(this, config) || this;\n\n    _this.kernel = null;\n    _this.bias = null;\n    _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    _this.rank = rank;\n\n    if (_this.rank !== 1 && _this.rank !== 2) {\n      throw new errors_1.NotImplementedError(\"Convolution layer for rank other than 1 or 2 (\" + _this.rank + \") is \" + \"not implemented yet.\");\n    }\n\n    _this.filters = config.filters;\n    _this.kernelSize = conv_utils_1.normalizeArray(config.kernelSize, rank, 'kernelSize');\n    _this.strides = conv_utils_1.normalizeArray(config.strides == null ? 1 : config.strides, rank, 'strides');\n    _this.padding = config.padding == null ? 'valid' : config.padding;\n    common_1.checkPaddingMode(_this.padding);\n    _this.dataFormat = config.dataFormat == null ? 'channelsLast' : config.dataFormat;\n    common_1.checkDataFormat(_this.dataFormat);\n    _this.dilationRate = config.dilationRate == null ? 1 : config.dilationRate;\n\n    if (_this.rank === 1 && Array.isArray(_this.dilationRate) && _this.dilationRate.length !== 1) {\n      throw new errors_1.ValueError(\"dilationRate must be a number or an array of a single number \" + \"for 1D convolution, but received \" + (\"\" + JSON.stringify(_this.dilationRate)));\n    }\n\n    if (_this.rank === 2) {\n      if (typeof _this.dilationRate === 'number') {\n        _this.dilationRate = [_this.dilationRate, _this.dilationRate];\n      } else if (_this.dilationRate.length !== 2) {\n        throw new errors_1.ValueError(\"dilationRate must be a number or array of two numbers for 2D \" + (\"convolution, but received \" + JSON.stringify(_this.dilationRate)));\n      }\n    }\n\n    _this.activation = activations_1.getActivation(config.activation);\n    _this.useBias = config.useBias == null ? true : config.useBias;\n    _this.kernelInitializer = initializers_1.getInitializer(config.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n    _this.biasInitializer = initializers_1.getInitializer(config.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n    _this.kernelConstraint = constraints_1.getConstraint(config.kernelConstraint);\n    _this.biasConstraint = constraints_1.getConstraint(config.biasConstraint);\n    _this.kernelRegularizer = regularizers_1.getRegularizer(config.kernelRegularizer);\n    _this.biasRegularizer = regularizers_1.getRegularizer(config.biasRegularizer);\n    _this.activityRegularizer = regularizers_1.getRegularizer(config.activityRegularizer);\n    return _this;\n  }\n\n  Conv.prototype.build = function (inputShape) {\n    inputShape = generic_utils.getExactlyOneShape(inputShape);\n    var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new errors_1.ValueError(\"The channel dimension of the input should be defined. \" + (\"Found \" + inputShape[channelAxis]));\n    }\n\n    var inputDim = inputShape[channelAxis];\n    var kernelShape = this.kernelSize.concat([inputDim, this.filters]);\n    this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.inputSpec = [{\n      ndim: this.rank + 2,\n      axes: (_a = {}, _a[channelAxis] = inputDim, _a)\n    }];\n    this.built = true;\n\n    var _a;\n  };\n\n  Conv.prototype.call = function (inputs, kwargs) {\n    inputs = generic_utils.getExactlyOneTensor(inputs);\n    var outputs;\n    var biasValue = this.bias == null ? null : this.bias.read();\n\n    if (this.rank === 1) {\n      outputs = K.conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate);\n    } else if (this.rank === 2) {\n      outputs = K.conv2dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n    } else if (this.rank === 3) {\n      throw new errors_1.NotImplementedError('3D convolution is not implemented yet.');\n    }\n\n    if (this.activation != null) {\n      outputs = this.activation(outputs);\n    }\n\n    return outputs;\n  };\n\n  Conv.prototype.computeOutputShape = function (inputShape) {\n    inputShape = generic_utils.getExactlyOneShape(inputShape);\n    var newSpace = [];\n    var space = this.dataFormat === 'channelsLast' ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);\n\n    for (var i = 0; i < space.length; ++i) {\n      var newDim = conv_utils_1.convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === 'number' ? this.dilationRate : this.dilationRate[i]);\n      newSpace.push(newDim);\n    }\n\n    var outputShape = [inputShape[0]];\n\n    if (this.dataFormat === 'channelsLast') {\n      outputShape = outputShape.concat(newSpace);\n      outputShape.push(this.filters);\n    } else {\n      outputShape.push(this.filters);\n      outputShape = outputShape.concat(newSpace);\n    }\n\n    return outputShape;\n  };\n\n  Conv.prototype.getConfig = function () {\n    var config = {\n      rank: this.rank,\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      strides: this.strides,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      activation: activations_1.serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n      biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n      kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n      biasConstraint: constraints_1.serializeConstraint(this.biasConstraint)\n    };\n\n    var baseConfig = _super.prototype.getConfig.call(this);\n\n    Object.assign(config, baseConfig);\n    return config;\n  };\n\n  return Conv;\n}(topology_1.Layer);\n\nexports.Conv = Conv;\n\nvar Conv2D = function (_super) {\n  __extends(Conv2D, _super);\n\n  function Conv2D(config) {\n    return _super.call(this, 2, config) || this;\n  }\n\n  Conv2D.prototype.getClassName = function () {\n    return 'Conv2D';\n  };\n\n  Conv2D.prototype.getConfig = function () {\n    var config = _super.prototype.getConfig.call(this);\n\n    delete config['rank'];\n    return config;\n  };\n\n  return Conv2D;\n}(Conv);\n\nexports.Conv2D = Conv2D;\ngeneric_utils.ClassNameMap.register('Conv2D', Conv2D);\n\nvar Conv2DTranspose = function (_super) {\n  __extends(Conv2DTranspose, _super);\n\n  function Conv2DTranspose(config) {\n    var _this = _super.call(this, config) || this;\n\n    _this.inputSpec = [new topology_1.InputSpec({\n      ndim: 4\n    })];\n\n    if (_this.padding !== 'same' && _this.padding !== 'valid') {\n      throw new errors_1.ValueError(\"Conv2DTranspose currently supports only padding modes 'same' \" + (\"and 'valid', but received padding mode \" + _this.padding));\n    }\n\n    return _this;\n  }\n\n  Conv2DTranspose.prototype.getClassName = function () {\n    return 'Conv2DTranspose';\n  };\n\n  Conv2DTranspose.prototype.build = function (inputShape) {\n    inputShape = generic_utils.getExactlyOneShape(inputShape);\n\n    if (inputShape.length !== 4) {\n      throw new errors_1.ValueError('Input should have rank 4; Received input shape: ' + JSON.stringify(inputShape));\n    }\n\n    var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new errors_1.ValueError('The channel dimension of the inputs should be defined. ' + 'Found `None`.');\n    }\n\n    var inputDim = inputShape[channelAxis];\n    var kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n    this.kernel = this.addWeight('kernel', kernelShape, types_1.DType.float32, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], types_1.DType.float32, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.inputSpec = [new topology_1.InputSpec({\n      ndim: 4,\n      axes: (_a = {}, _a[channelAxis] = inputDim, _a)\n    })];\n    this.built = true;\n\n    var _a;\n  };\n\n  Conv2DTranspose.prototype.call = function (inputs, kwargs) {\n    var _this = this;\n\n    return tfjs_core_1.tidy(function () {\n      var input = generic_utils.getExactlyOneTensor(inputs);\n\n      if (input.shape.length !== 4) {\n        throw new errors_1.ValueError(\"Conv2DTranspose.call() expects input tensor to be rank-4, but \" + (\"received a tensor of rank-\" + input.shape.length));\n      }\n\n      var inputShape = input.shape;\n      var batchSize = inputShape[0];\n      var hAxis;\n      var wAxis;\n\n      if (_this.dataFormat === 'channelsFirst') {\n        hAxis = 2;\n        wAxis = 3;\n      } else {\n        hAxis = 1;\n        wAxis = 2;\n      }\n\n      var height = inputShape[hAxis];\n      var width = inputShape[wAxis];\n      var kernelH = _this.kernelSize[0];\n      var kernelW = _this.kernelSize[1];\n      var strideH = _this.strides[0];\n      var strideW = _this.strides[1];\n      var outHeight = conv_utils_1.deconvLength(height, strideH, kernelH, _this.padding);\n      var outWidth = conv_utils_1.deconvLength(width, strideW, kernelW, _this.padding);\n      var outputShape = [batchSize, outHeight, outWidth, _this.filters];\n\n      if (_this.dataFormat !== 'channelsLast') {\n        input = K.transpose(input, [0, 2, 3, 1]);\n      }\n\n      var outputs = tfjs_core_1.conv2dTranspose(input, _this.kernel.read(), outputShape, _this.strides, _this.padding);\n\n      if (_this.dataFormat !== 'channelsLast') {\n        outputs = K.transpose(outputs, [0, 3, 1, 2]);\n      }\n\n      if (_this.bias != null) {\n        outputs = K.biasAdd(outputs, _this.bias.read(), _this.dataFormat);\n      }\n\n      if (_this.activation != null) {\n        outputs = _this.activation(outputs);\n      }\n\n      return outputs;\n    });\n  };\n\n  Conv2DTranspose.prototype.computeOutputShape = function (inputShape) {\n    inputShape = generic_utils.getExactlyOneShape(inputShape);\n    var outputShape = inputShape.slice();\n    var channelAxis;\n    var heightAxis;\n    var widthAxis;\n\n    if (this.dataFormat === 'channelsFirst') {\n      channelAxis = 1;\n      heightAxis = 2;\n      widthAxis = 3;\n    } else {\n      channelAxis = 3;\n      heightAxis = 1;\n      widthAxis = 2;\n    }\n\n    var kernelH = this.kernelSize[0];\n    var kernelW = this.kernelSize[1];\n    var strideH = this.strides[0];\n    var strideW = this.strides[1];\n    outputShape[channelAxis] = this.filters;\n    outputShape[heightAxis] = conv_utils_1.deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n    outputShape[widthAxis] = conv_utils_1.deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n    return outputShape;\n  };\n\n  Conv2DTranspose.prototype.getConfig = function () {\n    var config = _super.prototype.getConfig.call(this);\n\n    delete config['dilationRate'];\n    return config;\n  };\n\n  return Conv2DTranspose;\n}(Conv2D);\n\nexports.Conv2DTranspose = Conv2DTranspose;\ngeneric_utils.ClassNameMap.register('Conv2DTranspose', Conv2DTranspose);\n\nvar SeparableConv = function (_super) {\n  __extends(SeparableConv, _super);\n\n  function SeparableConv(rank, config) {\n    var _this = _super.call(this, rank, config) || this;\n\n    _this.DEFAULT_DEPTHWISE_INITIALIZER = 'glorotUniform';\n    _this.DEFAULT_POINTWISE_INITIALIZER = 'glorotUniform';\n    _this.depthwiseKernel = null;\n    _this.pointwiseKernel = null;\n\n    if (config.filters == null) {\n      throw new errors_1.ValueError('The `filters` configuration field is required by SeparableConv, ' + 'but is unspecified.');\n    }\n\n    if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {\n      throw new errors_1.ValueError('Fields kernelInitializer, kernelRegularizer and kernelConstraint ' + 'are invalid for SeparableConv2D. Use depthwiseInitializer, ' + 'depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, ' + 'pointwiseRegularizer and pointwiseConstraint instead.');\n    }\n\n    if (config.padding != null && config.padding !== 'same' && config.padding !== 'valid') {\n      throw new errors_1.ValueError(\"SeparableConv\" + _this.rank + \"D supports only padding modes: \" + (\"'same' and 'valid', but received \" + JSON.stringify(config.padding)));\n    }\n\n    _this.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;\n    _this.depthwiseInitializer = initializers_1.getInitializer(config.depthwiseInitializer || _this.DEFAULT_DEPTHWISE_INITIALIZER);\n    _this.depthwiseRegularizer = regularizers_1.getRegularizer(config.depthwiseRegularizer);\n    _this.depthwiseConstraint = constraints_1.getConstraint(config.depthwiseConstraint);\n    _this.pointwiseInitializer = initializers_1.getInitializer(config.depthwiseInitializer || _this.DEFAULT_POINTWISE_INITIALIZER);\n    _this.pointwiseRegularizer = regularizers_1.getRegularizer(config.pointwiseRegularizer);\n    _this.pointwiseConstraint = constraints_1.getConstraint(config.pointwiseConstraint);\n    return _this;\n  }\n\n  SeparableConv.prototype.build = function (inputShape) {\n    inputShape = generic_utils.getExactlyOneShape(inputShape);\n\n    if (inputShape.length < this.rank + 2) {\n      throw new errors_1.ValueError(\"Inputs to SeparableConv\" + this.rank + \"D should have rank \" + (this.rank + 2 + \", but received input shape: \") + (\"\" + JSON.stringify(inputShape)));\n    }\n\n    var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n      throw new errors_1.ValueError(\"The channel dimension of the inputs should be defined, \" + (\"but found \" + JSON.stringify(inputShape[channelAxis])));\n    }\n\n    var inputDim = inputShape[channelAxis];\n    var depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);\n    var pointwiseKernelShape = [];\n\n    for (var i = 0; i < this.rank; ++i) {\n      pointwiseKernelShape.push(1);\n    }\n\n    pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);\n    var trainable = true;\n    this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, types_1.DType.float32, this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);\n    this.pointwiseKernel = this.addWeight('pointwise_kernel', pointwiseKernelShape, types_1.DType.float32, this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);\n\n    if (this.useBias) {\n      this.bias = this.addWeight('bias', [this.filters], types_1.DType.float32, this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n\n    this.inputSpec = [new topology_1.InputSpec({\n      ndim: this.rank + 2,\n      axes: (_a = {}, _a[channelAxis] = inputDim, _a)\n    })];\n    this.built = true;\n\n    var _a;\n  };\n\n  SeparableConv.prototype.call = function (inputs, kwargs) {\n    inputs = generic_utils.getExactlyOneTensor(inputs);\n    var output;\n\n    if (this.rank === 1) {\n      throw new errors_1.NotImplementedError('1D separable convolution is not implemented yet.');\n    } else if (this.rank === 2) {\n      if (this.dataFormat === 'channelsFirst') {\n        inputs = K.transpose(inputs, [0, 2, 3, 1]);\n      }\n\n      output = tfjs_core_1.separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, 'NHWC');\n    }\n\n    if (this.useBias) {\n      output = K.biasAdd(output, this.bias.read(), this.dataFormat);\n    }\n\n    if (this.activation != null) {\n      output = this.activation(output);\n    }\n\n    if (this.dataFormat === 'channelsFirst') {\n      output = K.transpose(output, [0, 3, 1, 2]);\n    }\n\n    return output;\n  };\n\n  SeparableConv.prototype.getClassName = function () {\n    return 'SeparableConv';\n  };\n\n  SeparableConv.prototype.getConfig = function () {\n    var config = _super.prototype.getConfig.call(this);\n\n    delete config['rank'];\n    delete config['kernelInitializer'];\n    delete config['kernelRegularizer'];\n    delete config['kernelConstraint'];\n    config['depthwiseInitializer'] = initializers_1.serializeInitializer(this.depthwiseInitializer);\n    config['pointwiseInitializer'] = initializers_1.serializeInitializer(this.pointwiseInitializer);\n    config['depthwiseRegularizer'] = regularizers_1.serializeRegularizer(this.depthwiseRegularizer);\n    config['pointwiseRegularizer'] = regularizers_1.serializeRegularizer(this.pointwiseRegularizer);\n    config['depthwiseConstraint'] = constraints_1.serializeConstraint(this.depthwiseConstraint);\n    config['pointwiseConstraint'] = constraints_1.serializeConstraint(this.pointwiseConstraint);\n    return config;\n  };\n\n  return SeparableConv;\n}(Conv);\n\nexports.SeparableConv = SeparableConv;\n\nvar SeparableConv2D = function (_super) {\n  __extends(SeparableConv2D, _super);\n\n  function SeparableConv2D(config) {\n    return _super.call(this, 2, config) || this;\n  }\n\n  SeparableConv2D.prototype.getClassName = function () {\n    return 'SeparableConv2D';\n  };\n\n  return SeparableConv2D;\n}(SeparableConv);\n\nexports.SeparableConv2D = SeparableConv2D;\ngeneric_utils.ClassNameMap.register('SeparableConv2D', SeparableConv2D);\n\nvar Conv1D = function (_super) {\n  __extends(Conv1D, _super);\n\n  function Conv1D(config) {\n    var _this = _super.call(this, 1, config) || this;\n\n    _this.inputSpec = [{\n      ndim: 3\n    }];\n    return _this;\n  }\n\n  Conv1D.prototype.getClassName = function () {\n    return 'Conv1D';\n  };\n\n  Conv1D.prototype.getConfig = function () {\n    var config = _super.prototype.getConfig.call(this);\n\n    delete config['rank'];\n    delete config['dataFormat'];\n    return config;\n  };\n\n  return Conv1D;\n}(Conv);\n\nexports.Conv1D = Conv1D;\ngeneric_utils.ClassNameMap.register('Conv1D', Conv1D);","map":null,"metadata":{},"sourceType":"script"}